{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ1jamyVxnwr"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBrAsRcYxrCQ"
      },
      "source": [
        "Install missing modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH7SZr1OxJ-4",
        "outputId": "d49f6762-c4bc-4492-e896-feaecaf46321"
      },
      "outputs": [],
      "source": [
        "!pip install Keras-Applications\n",
        "!pip install xlrd==1.2.0\n",
        "!pip install loguru\n",
        "!pip install torchxrayvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AQLOlebxu-V"
      },
      "source": [
        "Clone BrixIA from Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBRh7KZjtzKc",
        "outputId": "e5590699-ebac-4f3d-8512-4addea07a789"
      },
      "outputs": [],
      "source": [
        "!git clone 'https://github.com/BrixIA/Brixia-score-COVID-19'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C3idXRox1d8"
      },
      "source": [
        "Include BrixIA in sys.path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "705rkd06tow9"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/Brixia-score-COVID-19/src\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iYYzpU2yCzx"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ii_GwpP_uQrW"
      },
      "outputs": [],
      "source": [
        "from BSNet.model import BSNet\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import linear_model\n",
        "import shutil\n",
        "import os\n",
        "from loguru import logger\n",
        "from skimage.segmentation import slic\n",
        "from skimage.draw import polygon_perimeter\n",
        "from skimage import measure\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchxrayvision as xrv\n",
        "\n",
        "BASE_PATH = \"/content/drive/Shareddrives/IDA covidcxr-hackaton/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6On4JXYTzLnV"
      },
      "source": [
        "Mount GDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd1kiFeNzK9G",
        "outputId": "83c40fba-5496-45ee-a7bb-7364e1fd78ca"
      },
      "outputs": [],
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXpQnsym7zbQ"
      },
      "source": [
        "# Utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l8PzhQq71IP"
      },
      "outputs": [],
      "source": [
        "def showImage(image, title):\n",
        "  \"\"\"\n",
        "  Shows an image adding the desired title\n",
        "  \n",
        "  Parameters\n",
        "  ----------\n",
        "  image: numpy.ndarray\n",
        "    The image to be shown\n",
        "  title: string\n",
        "    The title to be shown for the plotted image\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  None\n",
        "  \"\"\"\n",
        "  \n",
        "  if image.ndim == 2:\n",
        "    plt.imshow(image, cmap = 'gray', interpolation = 'bicubic', vmin=0, vmax=255)\n",
        "  else:\n",
        "    plt.imshow(image, interpolation = 'bicubic', vmin=0, vmax=255)\n",
        "    \n",
        "  plt.title(title)\n",
        "  plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXxG59Ud5v-5"
      },
      "outputs": [],
      "source": [
        "def readAndResize(path, size=(512,512)):\n",
        "  image = cv2.imread(path)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  return cv2.resize(image, size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf_YK-ENsCZA"
      },
      "outputs": [],
      "source": [
        "def imagePreprocessing(image, clip=0.01, median_filter_kernel_size=3, perc_low=2, perc_high=98):\n",
        "  '''\n",
        "  Given a 16 bit grayscale image, applys a series of preprocessing techniques and\n",
        "  returns an 8 bit grayscale image\n",
        "  '''\n",
        "\n",
        "  assert image[0][0].dtype == np.uint16\n",
        "  #Apply CLAHE\n",
        "  image = cv2.createCLAHE(clipLimit=clip * 8 * 8).apply(image) #8x8 is the window size\n",
        "  #Apply median blur\n",
        "  image = cv2.medianBlur(image, median_filter_kernel_size)\n",
        "  #Apply percentile stretching\n",
        "  hist = cv2.calcHist([image], [0], None, [65536], [0, 65536])\n",
        "  percent_low = image.shape[0] * image.shape[1] * perc_low / 100\n",
        "  percent_high = image.shape[0] * image.shape[1] * perc_high / 100\n",
        "  percentile_low = None\n",
        "  percentile_high = None\n",
        "  cumulative_value = 0\n",
        "  for index, val in enumerate(hist):\n",
        "    cumulative_value += val\n",
        "    if percentile_low == None and cumulative_value > percent_low:\n",
        "      percentile_low = index\n",
        "    if percentile_high == None and cumulative_value > percent_high:\n",
        "      percentile_high = index\n",
        "      break\n",
        "\n",
        "  alpha = (65535 / (percentile_high - percentile_low)) / 256 #normalize to 8 bit\n",
        "  beta = -percentile_low * alpha\n",
        "  return np.uint8(np.clip(np.float32(image) * alpha + beta, 0, 255))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOsGdo-tBgHt"
      },
      "source": [
        "Take as input a normalized image (0-1 pixel range) and returns a 0-255 image where only 0 and 255 values are allowed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiewwR_i4cFm"
      },
      "outputs": [],
      "source": [
        "def denormalizeImage(image):\n",
        "  return np.uint8(np.where(image<0.5, 0, 255))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwSmRWRzBzYB"
      },
      "source": [
        "Takes as input a list  of 9 images and optionally their titles and print them on a 3x3 grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3x5t9_t7WP1M"
      },
      "outputs": [],
      "source": [
        "def printExampleImages(images, titles=None, plots_grid = 3):\n",
        "  assert plots_grid ** 2 == len(images)\n",
        "  if titles != None:\n",
        "    assert len(images) == len(titles)\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  for i, image in enumerate(images):\n",
        "    ax = plt.subplot(plots_grid, plots_grid, i+1)\n",
        "    plt.imshow(image, cmap = 'gray', interpolation = 'bicubic', vmin=0, vmax=255)\n",
        "    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
        "    if titles != None:\n",
        "      ax.set_title(titles[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy0ZsX7gyxya"
      },
      "source": [
        "# Load the model with the weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3Gwje_My2RJ",
        "outputId": "eb3ba85d-c88f-4cab-cd17-8df25c17dbc4"
      },
      "outputs": [],
      "source": [
        "# Create the model with preloaded weights\n",
        "# MAE: 0.48\n",
        "model = BSNet(backbone_name='resnet18',\n",
        "              input_shape=(512, 512, 1),\n",
        "              input_tensor=None,\n",
        "              encoder_weights=None,\n",
        "              freeze_encoder=True,\n",
        "              skip_connections='default',\n",
        "              decoder_block_type='transpose',\n",
        "              decoder_filters=(256, 128, 64, 32, 16),\n",
        "              decoder_use_batchnorm=True,\n",
        "              n_upsample_blocks=5,\n",
        "              upsample_rates=(2, 2, 2, 2, 2),\n",
        "              classes=4,\n",
        "              activation='sigmoid',\n",
        "              load_seg_model=True,\n",
        "              seg_model_weights=BASE_PATH+'weights/segmentation-model.h5',\n",
        "              freeze_segmentation=True,\n",
        "              load_align_model=True,\n",
        "              align_model_weights=BASE_PATH+'weights/alignment-model.h5',\n",
        "              freeze_align_model=True,\n",
        "              pretrain_aligment_net=False,\n",
        "              explict_self_attention=True,\n",
        "              load_bscore_model=True,\n",
        "              bscore_model_weights=BASE_PATH+'weights/fpn_4lev_fliplr_ncl_loss03_correct_feat128-16-44.h5',\n",
        "              )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzyDK-5G6nyZ"
      },
      "source": [
        "Input layer shape: `[(None, 512, 512, 1)]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt2BAMXQ5ZOO"
      },
      "source": [
        "# BSNet example with an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "RX3a40oO7l1i",
        "outputId": "a4007a9a-3182-4044-9a2d-b5d99201b698"
      },
      "outputs": [],
      "source": [
        "image1 = readAndResize(BASE_PATH+'TrainSet/P_1_33.png')\n",
        "showImage(image1, 'Example image')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJDIyx3zDhzh"
      },
      "outputs": [],
      "source": [
        "in1 = np.expand_dims(image1, axis=2)\n",
        "in1 = np.expand_dims(in1, axis=0)\n",
        "\n",
        "in1 = in1/255\n",
        "\n",
        "out1 = model[0].predict(in1)\n",
        "out2 = model[1].predict(in1)\n",
        "out3 = model[2].predict(in1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OmLzcqJt_2I",
        "outputId": "2c38f1e6-3582-4a3c-a257-e49811f962b0"
      },
      "outputs": [],
      "source": [
        "out3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "8BnA-b5e0mp7",
        "outputId": "83e24ca2-9fa8-4e2c-fa43-821675ba3c67"
      },
      "outputs": [],
      "source": [
        "showImage(np.squeeze(np.squeeze(np.round(out1*255), axis=3), axis=0), \"Segmentation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKbzted-W0YE"
      },
      "outputs": [],
      "source": [
        "out3 = np.squeeze(out3, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNJQzw1UXWIr",
        "outputId": "2db54da9-ba5a-4d99-c017-555dcdaca097"
      },
      "outputs": [],
      "source": [
        "argmax = np.argmax(out3, axis = 2)\n",
        "argmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjQoV96bX16m",
        "outputId": "650a2ee3-4b2f-4173-81ca-ca230c55edf2"
      },
      "outputs": [],
      "source": [
        "np.max(out3, axis = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "KJVMB2XIY99J",
        "outputId": "fcc91f9b-e5cc-4b1a-83a0-5ecc5c435de5"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(argmax)\n",
        "# Loop over data dimensions and create text annotations.\n",
        "for i in range(argmax.shape[0]):\n",
        "    for j in range(argmax.shape[1]):\n",
        "        ax.text(j, i, argmax[i, j], ha=\"center\", va=\"center\", color=\"w\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GOtmIxkDwq9"
      },
      "source": [
        "# Preprocess example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO1YD_kDD3Gi"
      },
      "source": [
        "\"Adaptive histogram equalization (CLAHE, clip:0.01), a median filtering to cope with noise (kernel size: 3), and a clipping outside the 2nd and 98th percentile\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "SNsNFbLUGbyR",
        "outputId": "014fa6db-2da0-48ce-c44e-fe74391b1541"
      },
      "outputs": [],
      "source": [
        "image1 = readAndResize(BASE_PATH+'TrainSet/P_1_1.png')\n",
        "showImage(image1, 'Initial resized image')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "9nXv_67UDwKl",
        "outputId": "56603ac6-48d0-4ed5-af68-a1464e3bbe11"
      },
      "outputs": [],
      "source": [
        "clahe = cv2.createCLAHE(clipLimit=0.01*8*8) #8x8 is the window size\n",
        "image2 = clahe.apply(image1)\n",
        "showImage(image2, \"After CLAHE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "Aj-EaywUGXzG",
        "outputId": "f8410863-3476-450e-b3be-f683bd2c9470"
      },
      "outputs": [],
      "source": [
        "image3 = cv2.medianBlur(image2, 3)\n",
        "showImage(image3, \"After median filtering on a 3x3 window\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "g1Ew0mOzMTWi",
        "outputId": "e1880a12-684d-445b-fed3-329e2b3ffe04"
      },
      "outputs": [],
      "source": [
        "plt.hist(image3.ravel(),256,[0,256]); plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkQM1RMINBfI"
      },
      "outputs": [],
      "source": [
        "hist = cv2.calcHist([image3],[0],None,[256],[0,256])\n",
        "\n",
        "percent2 = 512*512*0.02\n",
        "percent98 = 512*512*0.98\n",
        "percentile2 = None\n",
        "percentile98 = None\n",
        "cumulative_value = 0\n",
        "\n",
        "for index, val in enumerate(hist):\n",
        "  cumulative_value += val\n",
        "  if percentile2 == None and cumulative_value > percent2:\n",
        "    percentile2 = index\n",
        "  if percentile98 == None and cumulative_value > percent98:\n",
        "    percentile98 = index\n",
        "\n",
        "alpha = 255 / (percentile98 - percentile2)\n",
        "beta = -255*percentile2 / (percentile98 - percentile2)\n",
        "\n",
        "image4 = cv2.convertScaleAbs(image3, None, alpha, beta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "3Gc-SfL5QH5A",
        "outputId": "a9e6209c-3dd0-4acd-8c6e-38cdc1848bb3"
      },
      "outputs": [],
      "source": [
        "showImage(image4, \"After clipping outside the 2nd and 98th percentile\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "RXFoUkpTQf8y",
        "outputId": "81822dc0-61a6-4158-c2d7-90715072dd8e"
      },
      "outputs": [],
      "source": [
        "plt.hist(image4.ravel(),256,[0,256]); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glsilLjmZQ5A"
      },
      "source": [
        "# Read Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgX5TdzKZQZj",
        "outputId": "30dcbd8d-4711-45c0-a5a4-fad717171098"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(BASE_PATH+'trainClinData.xls')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl_F9FqCCTY_"
      },
      "source": [
        "# Solving the issue with the images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "354E41nJCWeA"
      },
      "source": [
        "The images that the organizers provided to us are not ready to be fed to BSNet. They are in a `.png` format (and not dicom). Hence, all the additional metadata are missing. Practically, the issue with the images are the following:\n",
        "\n",
        "- Some of them are rotated\n",
        "- Some are taken in positive and some are taken in negative\n",
        "\n",
        "In the following we will investigate 2 tests that we can apply to the images, in particular to the segmentation mask, in order to understand if they are good, or can be adjusted or we can do nothing with the neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHHVV12CZLW7"
      },
      "source": [
        "## Lungs size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-i4waB9GaE3"
      },
      "source": [
        "In this section we try to discover the first trivial test: the lungs size. Are the 2 biggest blobs big enough to be considered 2 lungs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-wFPH5nGQ2M"
      },
      "source": [
        "### What happens to BSNet with incorrect images?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9XIeUdYFhJ_"
      },
      "source": [
        "Let's first understand what happen if you feed BSNet with an image that is not correct (e.g. is inverted or rotated)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmxkjEktZKNb"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 9\n",
        "preprocessed_images = np.empty((BATCH_SIZE, 512, 512), dtype=np.uint8)\n",
        "\n",
        "for index, image_path in enumerate(df[df.index < BATCH_SIZE].ImageFile):\n",
        "  image = readAndResize(BASE_PATH+'TrainSet/'+image_path)\n",
        "  image = imagePreprocessing(image)\n",
        "  preprocessed_images[index] = image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cc7OEAqpCC_K"
      },
      "outputs": [],
      "source": [
        "printExampleImages(preprocessed_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E4p6GlZCmcs"
      },
      "outputs": [],
      "source": [
        "input_images = np.empty((BATCH_SIZE, 512, 512, 1), dtype=np.float32)\n",
        "for i, image in enumerate(preprocessed_images):\n",
        "  input_images[i] = np.expand_dims(image / 255, axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQFZpjUEZgTw"
      },
      "outputs": [],
      "source": [
        "out_images = model[0].predict(input_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gooujogu_8zB"
      },
      "outputs": [],
      "source": [
        "chest_masks = np.empty((BATCH_SIZE, 512, 512), dtype=np.uint8)\n",
        "for i, image in enumerate(out_images):\n",
        "  image = np.squeeze(image, axis=2)\n",
        "  chest_masks[i] = denormalizeImage(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "oVNLTrhjbVkT",
        "outputId": "63f95a26-cfee-422e-b954-db4bbda6df9c"
      },
      "outputs": [],
      "source": [
        "printExampleImages(chest_masks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJnzvLmeGMP8"
      },
      "source": [
        "It seems that if the image is correct we get 2 segmentated lungs (as expected). But if the images are incorrect we get noise or even nothing.\n",
        "\n",
        "Be careful, this are just 9 images! Along all the thousand images there are more strange cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--Sfakht_tYs"
      },
      "source": [
        "### Erosion of the masks\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8d_Q500Hio9"
      },
      "source": [
        "Let's apply a little bit of erosion. The lungs stays lungs and we get rid of a little bit of noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLxARLGr_zRI"
      },
      "outputs": [],
      "source": [
        "eroded_images = np.empty((BATCH_SIZE, 512, 512), dtype=np.uint8)\n",
        "for i, image in enumerate(chest_masks):\n",
        "  eroded_images[i] = cv2.erode(image, np.ones((3,3), np.uint8), iterations=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "NAQOYMa1EY-O",
        "outputId": "0a083e21-550c-4474-8f75-02572dd053e4"
      },
      "outputs": [],
      "source": [
        "printExampleImages(eroded_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTZK7s9HG0OC"
      },
      "source": [
        "### Count the number of connected components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWfWMpy6MJw6"
      },
      "source": [
        "If we identify 2 regions with at least `num_pixels_lung` pixels (we have to exclude the background region) then the image is ok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieLzQdq8G4ZV"
      },
      "outputs": [],
      "source": [
        "num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(eroded_images[0], 8, cv2.CV_32S)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNVs1NTKI-F4",
        "outputId": "ed819c66-0397-4967-9421-39e9e5dd79e6"
      },
      "outputs": [],
      "source": [
        "stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMFcukuWInl4"
      },
      "source": [
        "In this vector the last column represent the number of pixel of the respective region.\n",
        "\n",
        "Be careful! The `stats` matrix is not sorted by the number of pixels!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "TnhErHMCJQ0H",
        "outputId": "3161cfab-fbb3-4992-863c-edb90768b414"
      },
      "outputs": [],
      "source": [
        "plt.imshow(labels, cmap = 'gray', interpolation = 'bicubic', vmin=0, vmax=num_labels-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njr3VcyRLXlE"
      },
      "source": [
        "### Adjust positive/negative images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AneTylYNIHMk"
      },
      "source": [
        "Here we try to combine everything we said unitl now in a function. If the image pass the test than the same image is returned, otherwise we invert it. Let's see the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9WQSRqbSF1k"
      },
      "outputs": [],
      "source": [
        "def adjust_positive_negative(image, num_pixels_lung=10000):\n",
        "  # Get the preprocessed image\n",
        "  initial_image = image\n",
        "  # Adapt to the dimensions requested by BSNet\n",
        "  image = np.expand_dims(np.expand_dims(initial_image / 255, axis=2), axis=0)\n",
        "  # Produce the binary mask\n",
        "  image = model[0].predict(image)\n",
        "  # Go back to 512x512 image format\n",
        "  image = np.squeeze(np.squeeze(image, axis=0), axis=2)\n",
        "  # Use the 0-255 pixel value range\n",
        "  image = denormalizeImage(image)\n",
        "  # Erode the mask\n",
        "  image = cv2.erode(image, np.ones((3,3), np.uint8), iterations=3)\n",
        "  # Find connected components\n",
        "  _, _, stats, _ = cv2.connectedComponentsWithStats(image, 8, cv2.CV_32S)\n",
        "  # Sort stats by the last column\n",
        "  argsort = np.argsort(stats[:, -1])[::-1]\n",
        "  stats = stats[argsort]\n",
        "  # If the first and the second region has at least 10000 pixel then it's ok\n",
        "  if(len(stats)>=3 and stats[1][-1] > num_pixels_lung and stats[2][-1] > num_pixels_lung):\n",
        "    return initial_image, False\n",
        "  return 255 - initial_image, True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "vysz-x2WTrYN",
        "outputId": "840f6db8-4096-4629-b3a6-3d18c92a9043"
      },
      "outputs": [],
      "source": [
        "printExampleImages(preprocessed_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "fpCTMdi-Typl",
        "outputId": "e6bc0e01-2c68-42bc-a957-cf8595333c64"
      },
      "outputs": [],
      "source": [
        "adjusted_images = np.empty_like(preprocessed_images)\n",
        "titles = []\n",
        "for i, image in enumerate(preprocessed_images):\n",
        "  adjusted_images[i], adjusted = adjust_positive_negative(image)\n",
        "  titles.append(\"Adjusted\" if adjusted else \"Already OK\")\n",
        "\n",
        "printExampleImages(adjusted_images, titles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN0-_TVaJ2sR"
      },
      "source": [
        "It seems that we are on the rigth path. But this is only a trivial test. We have no guarantees that 2 big blobs are 2 lungs, could be noise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKgI27VBV0Zm"
      },
      "source": [
        "## Lungs segmentation assessment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GVXJZe_K3aD"
      },
      "source": [
        "In this section we introduce another test. Are the 2 big blobs something similar to 2 lungs? We can try to use some information produced by `cv2.connectedComponentsWithStats()` in order to fit 2 lines on the 2 lungs and try to underestand if the lines converges in a point in a certain location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHRBnQYXWc0W"
      },
      "outputs": [],
      "source": [
        "input_images = np.empty((BATCH_SIZE, 512, 512, 1), dtype=np.float32)\n",
        "for i, image in enumerate(adjusted_images):\n",
        "  input_images[i] = np.expand_dims(image / 255, axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umru9OhMWc0X"
      },
      "outputs": [],
      "source": [
        "out_images = model[0].predict(input_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWHDlTC1Wc0Y"
      },
      "outputs": [],
      "source": [
        "chest_masks = np.empty((BATCH_SIZE, 512, 512), dtype=np.uint8)\n",
        "for i, image in enumerate(out_images):\n",
        "  image = np.squeeze(image, axis=2)\n",
        "  chest_masks[i] = denormalizeImage(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02VY3tloXRz5"
      },
      "outputs": [],
      "source": [
        "eroded_images = np.empty((BATCH_SIZE, 512, 512), dtype=np.uint8)\n",
        "for i, image in enumerate(chest_masks):\n",
        "  eroded_images[i] = cv2.erode(image, np.ones((3,3), np.uint8), iterations=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "9ZhjwUxIXij9",
        "outputId": "ed7fc827-a534-4466-ce24-5c758f23b35c"
      },
      "outputs": [],
      "source": [
        "printExampleImages(eroded_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "cb3a_WElkMnb",
        "outputId": "18edb4a9-51a8-4bdb-a12c-6b1b5e2a4273"
      },
      "outputs": [],
      "source": [
        "showImage(eroded_images[0], \"We will work on this image\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FIeDu2_YUYy"
      },
      "outputs": [],
      "source": [
        "num_regions, labels, _, _ = cv2.connectedComponentsWithStats(eroded_images[0], 8, cv2.CV_32S)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KTD6x-bKbug"
      },
      "outputs": [],
      "source": [
        "lung_1 = np.argwhere(labels==1)\n",
        "y_lung_1 = lung_1[:,0]\n",
        "x_lung_1 = lung_1[:,1]\n",
        "lung_2 = np.argwhere(labels==2)\n",
        "y_lung_2 = lung_2[:,0]\n",
        "x_lung_2 = lung_2[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnoX4587L8KZ"
      },
      "source": [
        "In the following we will try some techniques for line fitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8wS2vx8oeHG"
      },
      "source": [
        "### Least square"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsbIHQ_xc8q_",
        "outputId": "b6a59b44-3bcf-41fa-e53b-753165fb6599"
      },
      "outputs": [],
      "source": [
        "L_1 = np.polyfit(x_lung_1, -y_lung_1, 1)\n",
        "L_2 = np.polyfit(x_lung_2, -y_lung_2, 1)\n",
        "L_1, L_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8ZNCDHlSmpg"
      },
      "outputs": [],
      "source": [
        "x_intersection = (L_2[1]-L_1[1])/(L_1[0]-L_2[0])\n",
        "y_intersection = L_1[0]*x_intersection + L_1[1]\n",
        "intersection = np.array([x_intersection, y_intersection])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "U3T4Px4TiJPc",
        "outputId": "6e01e1c9-0c3f-422c-a3ab-face21f9a74c"
      },
      "outputs": [],
      "source": [
        "xp = np.linspace(0, 512, 513)\n",
        "p_1 = np.poly1d(L_1)\n",
        "p_2 = np.poly1d(L_2)\n",
        "plt.plot(x_lung_1, -y_lung_1, '.', xp, p_1(xp), '-', x_lung_2, -y_lung_2, '.', xp, p_2(xp), '-', intersection[0], intersection[1], 'o')\n",
        "plt.xlim([0, 512])\n",
        "plt.ylim([-512, 0])\n",
        "plt.axes().set_aspect('equal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnvhXfpiMSjq"
      },
      "source": [
        "Despite this image is very well segmentated, the line direction of the left lung is not perfect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1cnqOtIoiYZ"
      },
      "source": [
        "### RANSAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wstIIdIQn41q",
        "outputId": "7c7f3ab8-7071-42ff-ccf1-a4546a39a0f3"
      },
      "outputs": [],
      "source": [
        "ransac_1 = linear_model.RANSACRegressor(linear_model.LinearRegression())\n",
        "ransac_1.fit(x_lung_1.reshape(-1,1), -y_lung_1)\n",
        "\n",
        "ransac_2 = linear_model.RANSACRegressor(linear_model.LinearRegression())\n",
        "ransac_2.fit(x_lung_2.reshape(-1,1), -y_lung_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GA1_nEHNanS",
        "outputId": "fba1a8a7-b7a4-4543-dc7d-53e772b80592"
      },
      "outputs": [],
      "source": [
        "R_1 = np.array([ransac_1.estimator_.coef_[0], ransac_1.predict([[0]])[0]])\n",
        "R_2 = np.array([ransac_2.estimator_.coef_[0], ransac_2.predict([[0]])[0]])\n",
        "R_1, R_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-nBNs3-SBr6"
      },
      "outputs": [],
      "source": [
        "x_intersection = (R_2[1]-R_1[1])/(R_1[0]-R_2[0])\n",
        "y_intersection = R_1[0]*x_intersection + R_1[1]\n",
        "intersection = np.array([x_intersection, y_intersection])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "sbr78oabNuzC",
        "outputId": "dc5aa995-e323-4ca2-fcb3-51d0f999e4ca"
      },
      "outputs": [],
      "source": [
        "xp = np.linspace(0, 512, 513)\n",
        "p_1 = np.poly1d(R_1)\n",
        "p_2 = np.poly1d(R_2)\n",
        "plt.plot(x_lung_1, -y_lung_1, '.', xp, p_1(xp), '-', x_lung_2, -y_lung_2, '.', xp, p_2(xp), '-', intersection[0], intersection[1], 'o')\n",
        "plt.xlim([0, 512])\n",
        "plt.ylim([-512, 0])\n",
        "plt.axes().set_aspect('equal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fdDAlJWNr8o"
      },
      "source": [
        "With RANSAC we get a quite perfect line fitting on the 2 lungs. But let's try yet another technique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Wgu18jIkG9O"
      },
      "source": [
        "### Ellipse fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4OQDHv1ODqt"
      },
      "source": [
        "In this technique we try to perform an ellipse fitting on each of the two lungs. Then, we compute the line as the direction of the axe of the ellipse. Then we perform the same operations that we did before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZB1IIKkkcfO"
      },
      "outputs": [],
      "source": [
        "num_regions, labels, stats, _ = cv2.connectedComponentsWithStats(eroded_images[0], 8, cv2.CV_32S)\n",
        "# Sort stats by the last column\n",
        "argsort = np.argsort(stats[:, -1])[::-1]\n",
        "stats = stats[argsort]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "rWeXIzommFt2",
        "outputId": "c208f8f5-0e8c-4b5e-aba7-1b7bc1ee87ac"
      },
      "outputs": [],
      "source": [
        "lungs = np.uint8(np.where(np.logical_or(np.equal(labels, argsort[1]), np.equal(labels, argsort[2])), 255, 0))\n",
        "showImage(lungs, \"Lungs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "OuFrRExfkGpQ",
        "outputId": "845f39a4-886d-40de-d2ad-80d4860a451c"
      },
      "outputs": [],
      "source": [
        "canny_output = cv2.Canny(lungs, 100, 200)\n",
        "contours, _ = cv2.findContours(canny_output, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "# Keep just the 2 longest contours\n",
        "argsort_contour = np.argsort([len(val) for val in contours])[-2:]\n",
        "# Redefine contours with just the 2 longest contours\n",
        "contours = [contours[i] for i in argsort_contour]\n",
        "# Find the ellipses for each contour\n",
        "minEllipses = [None]*len(contours)\n",
        "for i, c in enumerate(contours):\n",
        "  if c.shape[0] > 5:\n",
        "    minEllipses[i] = cv2.fitEllipse(c)\n",
        "\n",
        "# Draw contours + rotated rects + ellipses\n",
        "    \n",
        "drawing = np.zeros((canny_output.shape[0], canny_output.shape[1], 3), dtype=np.uint8)\n",
        "    \n",
        "for i, c in enumerate(contours):\n",
        "  color = 255, 255, 255\n",
        "  # contour\n",
        "  cv2.drawContours(drawing, contours, i, color)\n",
        "  # ellipse\n",
        "  if c.shape[0] > 5:\n",
        "    cv2.ellipse(drawing, minEllipses[i], color, 2)\n",
        "showImage(drawing, \"Fitted ellipse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlJiGD6k00i4",
        "outputId": "8e8a98db-1ccb-4a25-8689-d2af7e2fceac"
      },
      "outputs": [],
      "source": [
        "minEllipses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4YBr79StsEf"
      },
      "source": [
        "This is \n",
        "- center\tThe rectangle mass center.\n",
        "- size\tWidth and height of the rectangle.\n",
        "- angle\tThe rotation angle in a clockwise direction. When the angle is 0, 90, 180, 270 etc., the rectangle becomes an up-right rectangle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cw2c8cOVtxH-"
      },
      "outputs": [],
      "source": [
        "slope_1 = np.tan(np.deg2rad(90 - minEllipses[0][2]))\n",
        "slope_2 = np.tan(np.deg2rad(90 - minEllipses[1][2]))\n",
        "intercept_1 = -minEllipses[0][0][1] - slope_1 * minEllipses[0][0][0]\n",
        "intercept_2 = -minEllipses[1][0][1] - slope_2 * minEllipses[1][0][0]\n",
        "\n",
        "x_intersection = (intercept_2 - intercept_1) / (slope_1 - slope_2)\n",
        "y_intersection = slope_1 * x_intersection + intercept_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnGWuraZy-Zn"
      },
      "outputs": [],
      "source": [
        "lungs_points = np.argwhere(np.logical_or(np.equal(labels, argsort[1]), np.equal(labels, argsort[2])))\n",
        "y_lungs = lungs_points[:,0]\n",
        "x_lungs = lungs_points[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "-bAH9iJgzJnv",
        "outputId": "43c0a1f2-f6f4-48df-88ee-5e9dc1cc3060"
      },
      "outputs": [],
      "source": [
        "xc = np.arange(0, 512)\n",
        "p_1 = np.poly1d([slope_1, intercept_1])\n",
        "p_2 = np.poly1d([slope_2, intercept_2])\n",
        "\n",
        "plt.plot(x_lungs, -y_lungs, '.', xc, p_1(xc), '-', xc, p_2(xc), '-', x_intersection, y_intersection, 'o')\n",
        "plt.xlim([0, 512])\n",
        "plt.ylim([-512, 200])\n",
        "plt.axes().set_aspect('equal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5QRVccfO6r1"
      },
      "source": [
        "Well it seems that the result is even more accurate than RANSAC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-kAwWShd0xD"
      },
      "source": [
        "## Definition of a compact function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfR1qodwPOOx"
      },
      "source": [
        "Here we define a function that did everything we did in the last 3 subsections. You can specify the technique you want and you can even submit precomputed `connectedComponents` (we will see why this is useful in the following sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vdqyd6FHQHNW"
      },
      "outputs": [],
      "source": [
        "def assess_lungs_direction(image, connectedComponents=None, assessment_mode=\"ellipse_fitting\") -> bool:\n",
        "  if connectedComponents is None:\n",
        "    num_regions, labels, stats, _ = cv2.connectedComponentsWithStats(image, 8, cv2.CV_32S)\n",
        "  else:\n",
        "    num_regions, labels, stats, _ = connectedComponents\n",
        "  \n",
        "  if num_regions < 3:\n",
        "    return False\n",
        "  argsort = np.argsort(stats[:, -1])[::-1]\n",
        "\n",
        "  if assessment_mode == \"least_square\":\n",
        "    lung_1 = np.argwhere(labels==argsort[1])\n",
        "    y_lung_1 = lung_1[:,0]\n",
        "    x_lung_1 = lung_1[:,1]\n",
        "    lung_2 = np.argwhere(labels==argsort[2])\n",
        "    y_lung_2 = lung_2[:,0]\n",
        "    x_lung_2 = lung_2[:,1]\n",
        "    slope_1, intercept_1 = np.polyfit(x_lung_1, -y_lung_1, 1)\n",
        "    slope_2, intercept_2 = np.polyfit(x_lung_2, -y_lung_2, 1)\n",
        "\n",
        "  elif assessment_mode == \"ransac\":\n",
        "    lung_1 = np.argwhere(labels==argsort[1])\n",
        "    y_lung_1 = lung_1[:,0]\n",
        "    x_lung_1 = lung_1[:,1]\n",
        "    lung_2 = np.argwhere(labels==argsort[2])\n",
        "    y_lung_2 = lung_2[:,0]\n",
        "    x_lung_2 = lung_2[:,1]\n",
        "    ransac_1 = linear_model.RANSACRegressor(linear_model.LinearRegression())\n",
        "    ransac_1.fit(x_lung_1.reshape(-1,1), -y_lung_1)\n",
        "    ransac_2 = linear_model.RANSACRegressor(linear_model.LinearRegression())\n",
        "    ransac_2.fit(x_lung_2.reshape(-1,1), -y_lung_2)\n",
        "    slope_1 = ransac_1.estimator_.coef_[0]\n",
        "    slope_2 = ransac_2.estimator_.coef_[0]\n",
        "    intercept_1 = ransac_1.predict([[0]])[0]\n",
        "    intercept_2 = ransac_2.predict([[0]])[0]\n",
        "\n",
        "  elif assessment_mode == \"ellipse_fitting\":\n",
        "    lungs = np.uint8(np.where(np.logical_or(np.equal(labels, argsort[1]), np.equal(labels, argsort[2])), 255, 0))\n",
        "    canny_output = cv2.Canny(lungs, 100, 200)\n",
        "    contours, _ = cv2.findContours(canny_output, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    # Keep just the 2 longest contours\n",
        "    argsort_contour = np.argsort([len(val) for val in contours])[-2:]\n",
        "    # Redefine contours with just the 2 longest contours\n",
        "    contours = [contours[i] for i in argsort_contour]\n",
        "    # Find the ellipses for each contour\n",
        "    minEllipses = [None]*len(contours)\n",
        "    for i, c in enumerate(contours):\n",
        "      if c.shape[0] > 5:\n",
        "        minEllipses[i] = cv2.fitEllipse(c)\n",
        "    slope_1 = np.tan(np.deg2rad(90 - minEllipses[0][2]))\n",
        "    slope_2 = np.tan(np.deg2rad(90 - minEllipses[1][2]))\n",
        "    intercept_1 = -minEllipses[0][0][1] - slope_1 * minEllipses[0][0][0]\n",
        "    intercept_2 = -minEllipses[1][0][1] - slope_2 * minEllipses[1][0][0]\n",
        "\n",
        "  else:\n",
        "    raise ValueError('assessment_mode must be either least_square, ransac or ellipse_fitting')\n",
        "\n",
        "  x_intersection = (intercept_2 - intercept_1) / (slope_1 - slope_2)\n",
        "  y_intersection = slope_1 * x_intersection + intercept_1\n",
        "\n",
        "  if y_intersection > -256 and x_intersection > 0 and x_intersection < 512:\n",
        "    return True\n",
        "  return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9wk7cqsJlv9",
        "outputId": "7542e40e-d255-4c52-87c1-35beecfbaf24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 loops, best of 5: 63.2 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%timeit [\"OK\" if assess_lungs_direction(image, \"least_square\") else \"NOT OK\" for image in eroded_images]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPlfevqNJqz6",
        "outputId": "2a67079a-a113-46e9-eab8-cd84d9870788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 loops, best of 5: 195 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%timeit [\"OK\" if assess_lungs_direction(image, \"ransac\") else \"NOT OK\" for image in eroded_images]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP5GMBbzJc4u",
        "outputId": "041f0de3-4f5b-453f-c707-9c656b60b7b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 loops, best of 5: 28.1 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%timeit [\"OK\" if assess_lungs_direction(image, \"ellipse_fitting\") else \"NOT OK\" for image in eroded_images]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUrGmikuY5Z8"
      },
      "outputs": [],
      "source": [
        "titles = [\"OK\" if assess_lungs_direction(image, \"ellipse_fitting\") else \"NOT OK\" for image in eroded_images]\n",
        "printExampleImages(eroded_images, titles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzuyBtiiPz34"
      },
      "source": [
        "Guess what, ellipse fitting is the fastest tecnique (and even by a big margin). Plus we can say that after many tests it is sligthy more accurate than RANSAC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUma8_s7goL8"
      },
      "source": [
        "# Adjust the images on TrainSet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kZ_K-DfKO8E"
      },
      "source": [
        "At the moment we introduced 2 tests in order to understand if the segmentated images are good. Now let's try to adjust the images with the help of the 2 previous tests.\n",
        "\n",
        "How many possibile correction can we apply to the images? 4 possibile rotation and each of them could be inverted or not. So they are just 8 possibile combination. And if we take a look to the images most of them are no rotated, so we have just to invert them. In this case a bruteforce approach is one of the easier thing we can do. What does it mean?\n",
        "\n",
        "\n",
        "1.   The input image pass all the tests? Return it\n",
        "2.   Otherwise **invert** it. Now it pass all the tests? Return it\n",
        "3.   Otherwise **rotate** it. Now it pass all the tests? Return it\n",
        "4.   Otherwise **invert** it. Now it pass all the tests? Return it\n",
        "5.   Otherwise **rotate** it. Now it pass all the tests? Return it\n",
        "6.   Otherwise **invert** it. Now it pass all the tests? Return it\n",
        "7.   Otherwise **rotate** it. Now it pass all the tests? Return it\n",
        "8.   Otherwise **invert** it. Now it pass all the tests? Return it\n",
        "9.   Otherwise it is **unrecoverable**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VepYijCwhlYl"
      },
      "outputs": [],
      "source": [
        "#Brute-force lungs segmentation assessment\n",
        "def adjust_preprocessed_image(image, num_pixels_lung=10000):\n",
        "  # Adapt to the dimensions requested by BSNet\n",
        "  adapted_image = np.expand_dims(np.expand_dims(image / 255, axis=2), axis=0)\n",
        "  # most images are not rotated (0), few of them are rotate buy just 90 degrees (3, 1),\n",
        "  # almost none of them are rotated by 180 degree (2)\n",
        "  for rotation_count in [0, 3, 1, 2]:\n",
        "    rotated_image = np.rot90(adapted_image, k=rotation_count, axes=(1,2))\n",
        "    print(\"Rotation count \", rotation_count)\n",
        "    for pos_neg in [False, True]:\n",
        "      if pos_neg:\n",
        "        print(\"Inverting...\")\n",
        "        rotated_image = 1 - rotated_image\n",
        "      print(\"Computing the segmentation...\")\n",
        "      mask = model[0].predict(rotated_image)\n",
        "      print(\"Components size assessment...\")\n",
        "      # Go back to 512x512 image format\n",
        "      mask = np.squeeze(np.squeeze(mask, axis=0), axis=2)\n",
        "      # Use the 0-255 pixel value range\n",
        "      mask = denormalizeImage(mask)\n",
        "      # Erode the mask\n",
        "      mask = cv2.erode(mask, np.ones((3,3), np.uint8), iterations=3)\n",
        "      # Find connected components\n",
        "      connectedComponents = cv2.connectedComponentsWithStats(mask, 8, cv2.CV_32S)\n",
        "      num_regions, _, stats, _ = connectedComponents\n",
        "      # Sort stats by the last column\n",
        "      argsort = np.argsort(stats[:, -1])[::-1]\n",
        "      stats = stats[argsort]\n",
        "      # If the first and the second region has at least 10000 pixel then it's ok\n",
        "      if num_regions>=3 and stats[1][-1] > num_pixels_lung and stats[2][-1] > num_pixels_lung:\n",
        "        print(\"Components size OK\\n Computing lungs direction\")\n",
        "        if(assess_lungs_direction(mask, connectedComponents=connectedComponents, assessment_mode=\"ellipse_fitting\")):\n",
        "          print(\"Lungs direction OK\")\n",
        "          return np.squeeze(np.squeeze(np.uint8(rotated_image * 255), axis = 0), axis = 2)\n",
        "  return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c26KcDO2abr2"
      },
      "source": [
        "## Example with one image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "MqbqMte5rid6",
        "outputId": "03114f43-8854-4455-871b-6bed79fcb803"
      },
      "outputs": [],
      "source": [
        "exampleImage = cv2.imread(BASE_PATH+\"TrainSetPreprocessed/P_1_60.png\", 0)\n",
        "showImage(exampleImage, \"Preprocessed example image\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ6BpJMUSxIi"
      },
      "source": [
        "This is an example of rotated and inverted image, let's see if the algorithm adjust it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "kjnYaRxdZS5z",
        "outputId": "ddf0e324-6b2a-4434-c1b8-bd3b44cb14e1"
      },
      "outputs": [],
      "source": [
        "showImage(adjust_preprocessed_image(exampleImage), \"After correction\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEU2f-slaenf"
      },
      "source": [
        "## Apply to all the Training set and put adjusted images in a folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-Nc-gCmauar"
      },
      "source": [
        "This function is slighty different then the one above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGe8jVyohYD0"
      },
      "outputs": [],
      "source": [
        "#Brute-force lungs segmentation assessment\n",
        "def adjust_preprocessed_image(image, num_pixels_lung=10000):\n",
        "  # Adapt to the dimensions requested by BSNet\n",
        "  adapted_image = np.expand_dims(np.expand_dims(image / 255, axis=2), axis=0)\n",
        "  # most images are not rotated (0), few of them are rotate buy just 90 degrees (3, 1),\n",
        "  # almost none of them are rotated by 180 degree (2)\n",
        "  for rotation_count in [0, 3, 1, 2]:\n",
        "    rotated_image = np.rot90(adapted_image, k=rotation_count, axes=(1,2))\n",
        "    for pos_neg in [False, True]:\n",
        "      if pos_neg:\n",
        "        rotated_image = 1 - rotated_image\n",
        "      mask = model[0].predict(rotated_image)\n",
        "      # Go back to 512x512 image format\n",
        "      mask = np.squeeze(np.squeeze(mask, axis=0), axis=2)\n",
        "      # Use the 0-255 pixel value range\n",
        "      mask = denormalizeImage(mask)\n",
        "      # Erode the mask\n",
        "      mask = cv2.erode(mask, np.ones((3,3), np.uint8), iterations=3)\n",
        "      # Find connected components\n",
        "      connectedComponents = cv2.connectedComponentsWithStats(mask, 8, cv2.CV_32S)\n",
        "      num_regions, _, stats, _ = connectedComponents\n",
        "      # Sort stats by the last column\n",
        "      argsort = np.argsort(stats[:, -1])[::-1]\n",
        "      stats = stats[argsort]\n",
        "      # If the first and the second region has at least 10000 pixel then it's ok\n",
        "      if num_regions>=3 and stats[1][-1] > num_pixels_lung and stats[2][-1] > num_pixels_lung:\n",
        "        if assess_lungs_direction(mask, connectedComponents=connectedComponents, assessment_mode=\"ellipse_fitting\"):\n",
        "          return np.squeeze(np.squeeze(np.uint8(rotated_image * 255), axis = 0), axis = 2)\n",
        "  return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2Av4Ihlam_J",
        "outputId": "e59060c8-33d4-4414-db61-1ecfb7dda9f9"
      },
      "outputs": [],
      "source": [
        "file_names = os.listdir(BASE_PATH+\"TrainSetPreprocessed/\")\n",
        "\n",
        "for index, file_name in enumerate(file_names):\n",
        "  print(\"\\rProcessing: \"+str(index+1)+\"/\"+str(len(file_names)), end=\"\")\n",
        "  image = cv2.imread(BASE_PATH+'TrainSetPreprocessed/'+file_name, cv2.IMREAD_GRAYSCALE)\n",
        "  output_image = adjust_preprocessed_image(image)\n",
        "  if output_image is None:\n",
        "    shutil.copyfile(BASE_PATH+'TrainSetPreprocessed/'+file_name, BASE_PATH+'TrainSetNotAdjusted/'+file_name)\n",
        "  else:\n",
        "    cv2.imwrite(BASE_PATH+'TrainSetAdjusted/'+file_name, output_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz0zP3YvhhQY"
      },
      "source": [
        "Show all the images that has been discarded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6nfurLBdhm59",
        "outputId": "d125fe07-2ef6-4f82-bc05-4ddca29ebcc1"
      },
      "outputs": [],
      "source": [
        "file_names = os.listdir(BASE_PATH+\"TrainSetNotAdjusted/\")\n",
        "\n",
        "for index, file_name in enumerate(file_names):\n",
        "  #print(\"\\rProcessing: \"+str(index+1)+\"/\"+str(len(file_names)), end=\"\")\n",
        "  image = cv2.imread(BASE_PATH+'TrainSetPreprocessed/'+file_name, cv2.IMREAD_GRAYSCALE)\n",
        "  print(file_name)\n",
        "  showImage(image, file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwLdx3z3i2gb"
      },
      "outputs": [],
      "source": [
        "file_names = os.listdir(BASE_PATH+\"TrainSetNotAdjusted/\")\n",
        "\n",
        "images_to_discard = [\n",
        "                     \"P_296.png\",\n",
        "                     \"P_612.png\",\n",
        "                     \"P_423.png\",\n",
        "                     \"P_311.png\",\n",
        "                     \"P_159.png\",\n",
        "                     \"P_1_137.png\",\n",
        "                     \"P_270.png\",\n",
        "                     \"P_2_98.png\",\n",
        "                     \"P_141.png\",\n",
        "                     \"P_1_34.png\",\n",
        "                     \"P_476.png\",\n",
        "                     \"P_2_58.png\",\n",
        "                     \"P_2_116.png\",\n",
        "]\n",
        "\n",
        "images_to_keep = np.setdiff1d(np.array(file_names), np.array(images_to_discard)).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo5U2CkWmJZT"
      },
      "source": [
        "Move `images_to_keep` in TrainSetAdjusted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQg82aqymIyS"
      },
      "outputs": [],
      "source": [
        "for file_name in images_to_keep:\n",
        "  shutil.move(BASE_PATH+'TrainSetNotAdjusted/'+file_name, BASE_PATH+'TrainSetAdjusted/'+file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeSZn7jSo-2r"
      },
      "source": [
        "After manual inspection some images has been moved to `TrainSetNotAdjusted` and some other need to be inverted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgDOz8u2pG2V"
      },
      "outputs": [],
      "source": [
        "images_to_invert = [\n",
        "                    \"P_1_11.png\",\n",
        "                    \"P_1_13.png\",\n",
        "                    \"P_1_14.png\",\n",
        "                    \"P_1_41.png\",\n",
        "                    \"P_1_45.png\",\n",
        "                    \"P_1_50.png\",\n",
        "                    \"P_1_72.png\",\n",
        "                    \"P_1_114.png\",\n",
        "                    \"P_1_117.png\",\n",
        "                    \"P_1_129.png\",\n",
        "                    \"P_4.png\",\n",
        "                    \"P_9.png\",\n",
        "                    \"P_54.png\",\n",
        "                    \"P_82.png\",\n",
        "                    \"P_119.png\",\n",
        "                    \"P_128.png\",\n",
        "                    \"P_177.png\",\n",
        "                    \"P_209.png\",\n",
        "                    \"P_210.png\",\n",
        "                    \"P_253.png\",\n",
        "                    \"P_256.png\",\n",
        "                    \"P_268.png\",\n",
        "                    \"P_279.png\",\n",
        "                    \"P_297.png\",\n",
        "                    \"P_360.png\",\n",
        "                    \"P_371.png\",\n",
        "                    \"P_396.png\",\n",
        "                    \"P_429.png\",\n",
        "                    \"P_436.png\",\n",
        "                    \"P_464.png\",\n",
        "                    \"P_468.png\",\n",
        "                    \"P_475.png\",\n",
        "                    \"P_523.png\",\n",
        "                    \"P_526.png\",\n",
        "                    \"P_664.png\",\n",
        "                    \"P_686.png\",\n",
        "                    \"P_689.png\",\n",
        "                    \"P_695.png\",\n",
        "                    \"P_700.png\",\n",
        "                    \"P_712.png\",\n",
        "                    \"P_729.png\",\n",
        "                    \"P_734.png\",\n",
        "                    \"P_753.png\",\n",
        "                    \"P_758.png\",\n",
        "                    \"P_760.png\",\n",
        "                    \"P_787.png\",\n",
        "                    \"P_788.png\",\n",
        "                    \"P_796.png\",\n",
        "                    \"P_802.png\",\n",
        "                    \"P_812.png\",\n",
        "                    \"P_815.png\",\n",
        "                    \"P_823.png\",\n",
        "                    \"P_827.png\",\n",
        "                    \"P_837.png\",\n",
        "                    \"P_840.png\",\n",
        "                    \"P_841.png\",\n",
        "]\n",
        "\n",
        "# They seems a lot, but in this list there are a lot of images that has been\n",
        "# discarded from the algorithm\n",
        "\n",
        "#P_2_9, P_2_84, P_2_121, P_138, P_382, P_451, P_747, P_803 da girare, --> DONE\n",
        "#P308 da girare e invertire  --> DONE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nud-Mm5zNt2"
      },
      "source": [
        "Here we invert images that should be inverted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox2N3YyaxXoH"
      },
      "outputs": [],
      "source": [
        "for index, file_name in enumerate(images_to_invert):\n",
        "  print(file_name)\n",
        "  image = cv2.imread(BASE_PATH+'TrainSetAdjusted/'+file_name, cv2.IMREAD_GRAYSCALE)\n",
        "  image = 255 - image\n",
        "  cv2.imwrite(BASE_PATH+'TrainSetAdjusted/'+file_name, image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIeKA_DGz_6G"
      },
      "source": [
        "After manual inspection some images need to be discarded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rceslawfzSaX"
      },
      "outputs": [],
      "source": [
        "images_to_discard = [\n",
        "                          \"P_2_11.png\",\n",
        "                          \"P_110.png\",\n",
        "                          \"P_269.png\",\n",
        "                          \"P_276.png\",\n",
        "                          \"P_445.png\",\n",
        "                          \"P_737.png\",\n",
        "]\n",
        "\n",
        "for file_name in images_to_discard:\n",
        "  shutil.move(BASE_PATH+'TrainSetAdjusted/'+file_name, BASE_PATH+'TrainSetNotAdjusted/'+file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwlfThPlDkw0"
      },
      "source": [
        "# Adjust the images on TestSet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKxnnHldE6_g"
      },
      "source": [
        "Slighty different then the one above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDQyglQoDh20"
      },
      "outputs": [],
      "source": [
        "#Brute-force lungs segmentation assessment\n",
        "def adjust_preprocessed_image(image, num_pixels_lung=10000):\n",
        "  # Adapt to the dimensions requested by BSNet\n",
        "  adapted_image = np.expand_dims(np.expand_dims(image / 255, axis=2), axis=0)\n",
        "  # most images are not rotated (0), few of them are rotate buy just 90 degrees (3, 1),\n",
        "  # almost none of them are rotated by 180 degree (2)\n",
        "  for rotation_count in [0]:\n",
        "    rotated_image = np.rot90(adapted_image, k=rotation_count, axes=(1,2))\n",
        "    for pos_neg in [False, True]:\n",
        "      if pos_neg:\n",
        "        rotated_image = 1 - rotated_image\n",
        "      mask = model[0].predict(rotated_image)\n",
        "      # Go back to 512x512 image format\n",
        "      mask = np.squeeze(np.squeeze(mask, axis=0), axis=2)\n",
        "      # Use the 0-255 pixel value range\n",
        "      mask = denormalizeImage(mask)\n",
        "      # Erode the mask\n",
        "      mask = cv2.erode(mask, np.ones((3,3), np.uint8), iterations=3)\n",
        "      # Find connected components\n",
        "      connectedComponents = cv2.connectedComponentsWithStats(mask, 8, cv2.CV_32S)\n",
        "      num_regions, _, stats, _ = connectedComponents\n",
        "      # Sort stats by the last column\n",
        "      argsort = np.argsort(stats[:, -1])[::-1]\n",
        "      stats = stats[argsort]\n",
        "      # If the first and the second region has at least 10000 pixel then it's ok\n",
        "      if num_regions>=3 and stats[1][-1] > num_pixels_lung and stats[2][-1] > num_pixels_lung:\n",
        "        if assess_lungs_direction(mask, connectedComponents=connectedComponents, assessment_mode=\"ellipse_fitting\"):\n",
        "          return np.squeeze(np.squeeze(np.uint8(rotated_image * 255), axis = 0), axis = 2)\n",
        "  return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvL9H2VYDh22",
        "outputId": "5d335ca7-3a7a-4629-c1c2-5d550583195b"
      },
      "outputs": [],
      "source": [
        "file_names = os.listdir(BASE_PATH+\"TestSetPreprocessed/\")\n",
        "\n",
        "for index, file_name in enumerate(file_names):\n",
        "  print(\"\\rProcessing: \"+str(index+1)+\"/\"+str(len(file_names)), end=\"\")\n",
        "  image = cv2.imread(BASE_PATH+'TestSetPreprocessed/'+file_name, cv2.IMREAD_GRAYSCALE)\n",
        "  output_image = adjust_preprocessed_image(image)\n",
        "  if output_image is None:\n",
        "    shutil.copyfile(BASE_PATH+'TestSetPreprocessed/'+file_name, BASE_PATH+'TestSetNotAdjusted/'+file_name)\n",
        "  else:\n",
        "    cv2.imwrite(BASE_PATH+'TestSetAdjusted/'+file_name, output_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZBtlTXzDh23"
      },
      "source": [
        "Show all the images that has been discarded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fhBPvXSiDh24",
        "outputId": "5c5be955-968b-408d-d85a-ba780a1c4154"
      },
      "outputs": [],
      "source": [
        "file_names = os.listdir(BASE_PATH+\"TestSetNotAdjusted/\")\n",
        "\n",
        "for index, file_name in enumerate(file_names):\n",
        "  #print(\"\\rProcessing: \"+str(index+1)+\"/\"+str(len(file_names)), end=\"\")\n",
        "  image = cv2.imread(BASE_PATH+'TestSetPreprocessed/'+file_name, cv2.IMREAD_GRAYSCALE)\n",
        "  print(file_name)\n",
        "  showImage(image, file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP8s_7hZDh24"
      },
      "outputs": [],
      "source": [
        "file_names = os.listdir(BASE_PATH+\"TestSetNotAdjusted/\")\n",
        "\n",
        "images_to_discard = [\n",
        "                     \"P_3_335.png\",\n",
        "]\n",
        "\n",
        "images_to_keep = np.setdiff1d(np.array(file_names), np.array(images_to_discard)).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLykpMrEDh24"
      },
      "source": [
        "Move `images_to_keep` in TrainSetAdjusted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "admtKu_6Dh24"
      },
      "outputs": [],
      "source": [
        "for file_name in images_to_keep:\n",
        "  image = cv2.imread(BASE_PATH + \"TestSetNotAdjusted/\" + file_name, cv2.IMREAD_GRAYSCALE)\n",
        "  image = 255 - image   #invert before moving\n",
        "  cv2.imwrite(BASE_PATH + \"TestSetAdjusted/\" + file_name, image)\n",
        "  os.remove(BASE_PATH + \"TestSetNotAdjusted/\" + file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtF9wUESDh25"
      },
      "source": [
        "After manual inspection some images has been moved to `TestSetNotAdjusted` and some other need to be inverted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC35wc89Dh25"
      },
      "outputs": [],
      "source": [
        "images_to_invert = [\n",
        "                    \"P_3_99.png\",\n",
        "                    \"P_3_184.png\",\n",
        "                    \"P_3_213.png\",\n",
        "                    \"P_3_336.png\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eV4Zs3DDh25"
      },
      "source": [
        "Here we invert images that should be inverted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqsbokYNDh25",
        "outputId": "1f1b12b9-6be2-47ae-a414-5466de14849a"
      },
      "outputs": [],
      "source": [
        "for index, file_name in enumerate(images_to_invert):\n",
        "  print(file_name)\n",
        "  image = cv2.imread(BASE_PATH+'TestSetAdjusted/'+file_name, cv2.IMREAD_GRAYSCALE)\n",
        "  image = 255 - image\n",
        "  cv2.imwrite(BASE_PATH+'TestSetAdjusted/'+file_name, image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtOYXnh_LPEM"
      },
      "source": [
        "# Compute the BS score on the Training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8or4gSQLPEN"
      },
      "source": [
        "Now let's compute the BS-score on the adjusted images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoeJQBmfLPEO",
        "outputId": "543c522e-82bb-4c3a-9948-59f8afafd44b"
      },
      "outputs": [],
      "source": [
        "DF_SIZE = len(df)\n",
        "\n",
        "correctness = np.zeros((DF_SIZE), dtype=np.uint8)\n",
        "bs_score = np.empty((DF_SIZE, 3, 2, 4), dtype=np.float32)\n",
        "\n",
        "for index, image_path in enumerate(df.ImageFile):\n",
        "  print(\"\\rProcessing: \"+str(index+1)+\"/\"+str(DF_SIZE), end=\"\")\n",
        "\n",
        "  file_path = BASE_PATH+'TrainSetAdjusted/'+image_path\n",
        "  # if the image exists in that folder then it is ok, otherwise it means that\n",
        "  # it has been discarded in the previous stage\n",
        "  if os.path.exists(file_path):\n",
        "    image = np.expand_dims(np.expand_dims(cv2.imread(file_path, cv2.IMREAD_GRAYSCALE), axis = 0), axis = 3) / 255\n",
        "    correctness[index] = 1\n",
        "    bs_score[index] = np.squeeze(model[-1].predict(image), axis = 0)\n",
        "  else:\n",
        "    correctness[index] = 0\n",
        "    bs_score[index].fill(0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB8aMpKcLPEP",
        "outputId": "9e8767f1-cff8-4a19-b8be-8fd18dbc601b"
      },
      "outputs": [],
      "source": [
        "print(\"Amount of bad images: \"+str(DF_SIZE - np.count_nonzero(correctness))+\"/\"+str(DF_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXnm-ZIdLPEP"
      },
      "outputs": [],
      "source": [
        "argmax = np.argmax(bs_score, axis = 3)\n",
        "argmax = np.reshape(argmax, (DF_SIZE, 6))\n",
        "probabilities = np.max(bs_score, axis = 3)\n",
        "probabilities = np.reshape(probabilities, (DF_SIZE, 6))\n",
        "confidence = np.mean(probabilities, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "DbCoex2uLPEQ",
        "outputId": "8366f6f1-a9d8-4348-d9a9-26b4a22a6cbe"
      },
      "outputs": [],
      "source": [
        "for i in range(6):\n",
        "  df[\"Brixia_score_\"+str(i)] = argmax[:,i]\n",
        "\n",
        "for i in range(6):\n",
        "  df[\"Brixia_score_prob_\"+str(i)] = probabilities[:,i]\n",
        "\n",
        "df[\"Brixia_score_correctness\"] = correctness\n",
        "df[\"Brixia_score_confidence\"] = confidence\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0ud8mG_LPEQ",
        "outputId": "a212c238-012b-445a-d25a-5de01402733c"
      },
      "outputs": [],
      "source": [
        "df.Brixia_score_confidence.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGtUZw4yLPER",
        "outputId": "66c1877d-a5fa-41ae-8a52-00ba9cb828ba"
      },
      "outputs": [],
      "source": [
        "df.to_excel(BASE_PATH+\"trainClinData_brixiascore.xls\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "371NFD1K5WVt"
      },
      "source": [
        "# Compute the BS score on the Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dit2R9lTCUh"
      },
      "source": [
        "Now let's compute the BS-score on the adjusted images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86QCPIAV9Pyw",
        "outputId": "b12270e2-934e-410c-de3f-e3c577f8d5f0"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(BASE_PATH+\"testClinData.xls\")\n",
        "\n",
        "DF_SIZE = len(df)\n",
        "\n",
        "correctness = np.zeros((DF_SIZE), dtype=np.uint8)\n",
        "bs_score = np.empty((DF_SIZE, 3, 2, 4), dtype=np.float32)\n",
        "\n",
        "for index, image_path in enumerate(df.ImageFile):\n",
        "  print(\"\\rProcessing: \"+str(index+1)+\"/\"+str(DF_SIZE), end=\"\")\n",
        "\n",
        "  file_path = BASE_PATH+'TestSetAdjusted/'+image_path\n",
        "  # if the image exists in that folder then it is ok, otherwise it means that\n",
        "  # it has been discarded in the previous stage\n",
        "  if os.path.exists(file_path):\n",
        "    image = np.expand_dims(np.expand_dims(cv2.imread(file_path, cv2.IMREAD_GRAYSCALE), axis = 0), axis = 3) / 255\n",
        "    correctness[index] = 1\n",
        "    bs_score[index] = np.squeeze(model[-1].predict(image), axis = 0)\n",
        "  else:\n",
        "    correctness[index] = 0\n",
        "    bs_score[index].fill(0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq9XHAPT94Fj",
        "outputId": "9e43c370-e618-48ed-e93f-ee86897f8714"
      },
      "outputs": [],
      "source": [
        "print(\"Amount of bad images: \"+str(DF_SIZE - np.count_nonzero(correctness))+\"/\"+str(DF_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMCAIpbytqOL"
      },
      "outputs": [],
      "source": [
        "argmax = np.argmax(bs_score, axis = 3)\n",
        "argmax = np.reshape(argmax, (DF_SIZE, 6))\n",
        "probabilities = np.max(bs_score, axis = 3)\n",
        "probabilities = np.reshape(probabilities, (DF_SIZE, 6))\n",
        "confidence = np.mean(probabilities, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4xOTiPpwK2c",
        "outputId": "7c84d2fc-6b50-4bf4-e197-7060636682c2"
      },
      "outputs": [],
      "source": [
        "for i in range(6):\n",
        "  df[\"Brixia_score_\"+str(i)] = argmax[:,i]\n",
        "\n",
        "for i in range(6):\n",
        "  df[\"Brixia_score_prob_\"+str(i)] = probabilities[:,i]\n",
        "\n",
        "df[\"Brixia_score_correctness\"] = correctness\n",
        "df[\"Brixia_score_confidence\"] = confidence\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NCzLgik6Ll0",
        "outputId": "bea8a6d3-5698-48d1-874c-9353624dc8fd"
      },
      "outputs": [],
      "source": [
        "df.Brixia_score_confidence.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sj9vF7E02w7"
      },
      "outputs": [],
      "source": [
        "df.to_excel(BASE_PATH+\"testClinData_brixiascore.xls\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sdwXrzAN-Kc"
      },
      "source": [
        "## Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBa6-tObtAf0",
        "outputId": "ad1f0937-460d-4ad3-f211-e9d791cdbbd3"
      },
      "outputs": [],
      "source": [
        "heart_model = xrv.models.ResNet(weights=\"resnet50-res512-all\")\n",
        "heart_model.op_threshs = None # prevent pre-trained model calibration\n",
        "heart_model.model.fc = torch.nn.Linear(2048,1) # reinitialize classifier\n",
        "heart_model.load_state_dict(torch.load(BASE_PATH + 'best_metric_model_so_far.pth'))\n",
        "heart_model=heart_model.to(\"cuda\")\n",
        "heart_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7Nd7vmsC_Tp"
      },
      "outputs": [],
      "source": [
        "# Normalize image from -1024 to 1024\n",
        "def normalize(img, maxval=255, reshape=False):\n",
        "  \"\"\"Scales images to be roughly [-1024 1024].\"\"\"\n",
        "\n",
        "  if img.max() > maxval:\n",
        "    raise Exception(\"max image value ({}) higher than expected bound ({}).\".format(img.max(), maxval))\n",
        "\n",
        "  img = (2 * (img.astype(np.float32) / maxval) - 1.) * 1024\n",
        "\n",
        "  if reshape:\n",
        "    # Check that images are 2D arrays\n",
        "    if len(img.shape) > 2:\n",
        "      img = img[:, :, 0]\n",
        "    if len(img.shape) < 2:\n",
        "      print(\"error, dimension lower than 2 for image\")\n",
        "\n",
        "    # add color channel\n",
        "    img = img[None, :, :]\n",
        "\n",
        "  return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fiit5bENN3ST"
      },
      "source": [
        "## Example with one image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZksjVqqhvI0U"
      },
      "outputs": [],
      "source": [
        "#image = cv2.imread(BASE_PATH+\"TrainSetAdjusted/P_703.png\", cv2.IMREAD_GRAYSCALE)\n",
        "image = cv2.imread(BASE_PATH+\"TrainSetAdjusted/P_2_108.png\", cv2.IMREAD_GRAYSCALE)\n",
        "image = np.expand_dims(np.expand_dims(normalize(image) , axis=0), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-M95I61wrZx",
        "outputId": "641ec897-51d0-4b1f-ef6a-fabe4ad61f97"
      },
      "outputs": [],
      "source": [
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB51zU5gVUCl",
        "outputId": "c1179a7f-7702-4c62-a5b0-d01f7cb5596b"
      },
      "outputs": [],
      "source": [
        "np.min(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVCYsrEuuD4I",
        "outputId": "7457d63f-301d-4c38-f6be-541c89e72b36"
      },
      "outputs": [],
      "source": [
        "heart_model(torch.from_numpy(image).float().to(\"cuda\"))#.cpu().data.numpy()[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4xjCAAaOE6M"
      },
      "source": [
        "## Compute on all the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2bgOQDqKKpO",
        "outputId": "6659600e-955d-44d1-ac85-3c246e942e9a"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(BASE_PATH + \"trainClinData_brixiascore.xls\")\n",
        "\n",
        "DF_SIZE = len(df)\n",
        "\n",
        "heart_score = np.empty((DF_SIZE), dtype=np.float32)\n",
        "\n",
        "for index, image_path in enumerate(df.ImageFile):\n",
        "  print(\"\\rProcessing: \"+str(index+1)+\"/\"+str(DF_SIZE), end=\"\")\n",
        "\n",
        "  file_path = BASE_PATH+'TrainSetAdjusted/'+image_path\n",
        "  # if the image exists in that folder then it is ok, otherwise it means that\n",
        "  # it has been discarded in the previous stage\n",
        "  if os.path.exists(file_path):\n",
        "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "    image = np.expand_dims(np.expand_dims(normalize(image), axis = 0), axis = 0)\n",
        "    image = torch.from_numpy(image).float().to(\"cuda\")\n",
        "    heart_score[index] = heart_model(image).cpu().data.numpy()[0][0]\n",
        "  else:\n",
        "    heart_score[index] = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "ZyrudiDkNqBE",
        "outputId": "7bf186ab-4f6b-41af-933b-85ac81546894"
      },
      "outputs": [],
      "source": [
        "df[\"heart_score\"] = heart_score\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P-lNR8oPqkL",
        "outputId": "c779ddf0-056b-4df3-a2c2-5674058a86a7"
      },
      "outputs": [],
      "source": [
        "np.max(heart_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7MaDtJIPuiB",
        "outputId": "5edca772-513c-48ab-b4d7-319b031fd4f0"
      },
      "outputs": [],
      "source": [
        "np.min(heart_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3Ytm-F8OtrD"
      },
      "outputs": [],
      "source": [
        "df.to_excel(BASE_PATH+\"trainClinData_brixiascore_heartscore.xls\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzwqPqNx2ufi"
      },
      "source": [
        "# Process Test Set and compute the BS score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqYENlcIUjKk"
      },
      "source": [
        "Here we do the same thing we did with the training set but here we do it for the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "TeNPFIUz227F",
        "outputId": "7abada2a-7d72-4ec3-e5c9-824327b1d35e"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_excel(BASE_PATH+'testClinData.xls')\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjUBoyqc4eA7"
      },
      "outputs": [],
      "source": [
        "#Brute-force lungs segmentation assessment\n",
        "def adjust_preprocessed_image(image, num_pixels_lung=10000):\n",
        "  # Adapt to the dimensions requested by BSNet\n",
        "  adapted_image = np.expand_dims(np.expand_dims(image / 255, axis=2), axis=0)\n",
        "  # most images are not rotated (0), few of them are rotate buy just 90 degrees (3, 1),\n",
        "  # almost none of them are rotated by 180 degree (2)\n",
        "  for rotation_count in [0, 3, 1, 2]:\n",
        "    rotated_image = np.rot90(adapted_image, k=rotation_count, axes=(1,2))\n",
        "    for pos_neg in [False, True]:\n",
        "      if pos_neg:\n",
        "        rotated_image = 1 - rotated_image\n",
        "      mask = model[0].predict(rotated_image)\n",
        "      # Go back to 512x512 image format\n",
        "      mask = np.squeeze(np.squeeze(mask, axis=0), axis=2)\n",
        "      # Use the 0-255 pixel value range\n",
        "      mask = denormalizeImage(mask)\n",
        "      # Erode the mask\n",
        "      mask = cv2.erode(mask, np.ones((3,3), np.uint8), iterations=3)\n",
        "      # Find connected components\n",
        "      connectedComponents = cv2.connectedComponentsWithStats(mask, 8, cv2.CV_32S)\n",
        "      num_regions, _, stats, _ = connectedComponents\n",
        "      # Sort stats by the last column\n",
        "      argsort = np.argsort(stats[:, -1])[::-1]\n",
        "      stats = stats[argsort]\n",
        "      # If the first and the second region has at least 10000 pixel then it's ok\n",
        "      if num_regions>=3 and stats[1][-1] > num_pixels_lung and stats[2][-1] > num_pixels_lung:\n",
        "        if(assess_lungs_direction(mask, connectedComponents=connectedComponents, assessment_mode=\"ellipse_fitting\")):\n",
        "          return rotated_image\n",
        "  return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC7050UM4eBG",
        "outputId": "6327868e-2a20-42f6-ae75-c739eab7ec25"
      },
      "outputs": [],
      "source": [
        "DF_SIZE = len(df_test)\n",
        "\n",
        "correctness = np.zeros((DF_SIZE), dtype=np.uint8)\n",
        "bs_score = np.empty((DF_SIZE, 3, 2, 4), dtype=np.float32)\n",
        "\n",
        "for index, image_path in enumerate(df_test.ImageFile):\n",
        "  print(\"\\rProcessing: \"+str(index+1)+\"/\"+str(DF_SIZE), end=\"\")\n",
        "  image = cv2.imread(BASE_PATH+'TestSetPreprocessed/'+image_path, cv2.IMREAD_GRAYSCALE)\n",
        "  output_image = adjust_preprocessed_image(image)\n",
        "  if output_image is None:\n",
        "    correctness[index] = 0\n",
        "    bs_score[index].fill(0.25)\n",
        "  else:\n",
        "    correctness[index] = 1\n",
        "    bs_score[index] = np.squeeze(model[-1].predict(output_image), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmgPz2934eBH",
        "outputId": "031dfca9-71d1-4261-e71e-d4f15ffe026c"
      },
      "outputs": [],
      "source": [
        "print(\"Amount of bad images: \"+str(DF_SIZE - np.count_nonzero(correctness))+\"/\"+str(DF_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qANbJL4C4eBI"
      },
      "outputs": [],
      "source": [
        "argmax = np.argmax(bs_score, axis = 3)\n",
        "argmax = np.reshape(argmax, (DF_SIZE, 6))\n",
        "probabilities = np.max(bs_score, axis = 3)\n",
        "probabilities = np.reshape(probabilities, (DF_SIZE, 6))\n",
        "confidence = np.mean(probabilities, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "pTiFmwv16DQ-",
        "outputId": "6a6a4254-3778-4f66-9cbd-625401a7a884"
      },
      "outputs": [],
      "source": [
        "for i in range(6):\n",
        "  df_test[\"Brixia_score_\"+str(i)] = argmax[:,i]\n",
        "\n",
        "for i in range(6):\n",
        "  df_test[\"Brixia_score_prob_\"+str(i)] = probabilities[:,i]\n",
        "\n",
        "df_test[\"Brixia_score_correctness\"] = correctness\n",
        "df_test[\"Brixia_score_confidence\"] = confidence\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o1pjbsy6DQ_",
        "outputId": "245b9f72-b246-4610-a4cc-cbb5dad8c3aa"
      },
      "outputs": [],
      "source": [
        "df_test.to_excel(BASE_PATH+\"testClinData_brixiascore.xls\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLB3kSh38Fdk"
      },
      "source": [
        "## Visualize bad images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "GW35MAQh7e9V",
        "outputId": "7885cc27-adf4-4e8c-a1ba-c7253b47f849"
      },
      "outputs": [],
      "source": [
        "df_test_bad_images = df_test[df_test.Brixia_score_correctness == 0]\n",
        "df_test_bad_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoW9bYIF8IYz"
      },
      "outputs": [],
      "source": [
        "# Little bit different function then before. Doesn't rotate and always returns something\n",
        "def get_max_non_zero_image(image):\n",
        "  # Adapt to the dimensions requested by BSNet\n",
        "  adapted_image = np.expand_dims(np.expand_dims(image / 255, axis=2), axis=0)\n",
        "  # most images are not rotated (0), few of them are rotate buy just 90 degrees (3, 1),\n",
        "  # almost none of them are rotated by 180 degree (2)\n",
        "  max_non_zero_pixels = 0\n",
        "  max_non_zero_image = adapted_image\n",
        "  for rotation_count in [0]:#[0, 3, 1, 2]:\n",
        "    rotated_image = np.rot90(adapted_image, k=rotation_count, axes=(1,2))\n",
        "    for pos_neg in [False, True]:\n",
        "      if pos_neg:\n",
        "        rotated_image = 1 - rotated_image\n",
        "      mask = model[0].predict(rotated_image)\n",
        "      # Go back to 512x512 image format\n",
        "      mask = np.squeeze(np.squeeze(mask, axis=0), axis=2)\n",
        "      # Use the 0-255 pixel value range\n",
        "      mask = denormalizeImage(mask)\n",
        "      # Erode the mask\n",
        "      mask = cv2.erode(mask, np.ones((3,3), np.uint8), iterations=3)\n",
        "\n",
        "      non_zero_pixels = np.count_nonzero(mask)\n",
        "      if non_zero_pixels > max_non_zero_pixels:\n",
        "        max_non_zero_pixels = non_zero_pixels\n",
        "        max_non_zero_image = rotated_image\n",
        "  return max_non_zero_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6AjpY2n8IY0"
      },
      "outputs": [],
      "source": [
        "image_files = df_test_bad_images.ImageFile.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "r4Lsr8AQ8IY0",
        "outputId": "de23c6e0-7b82-4e68-e867-bda5c9802032"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 9\n",
        "\n",
        "for stride in range(int(len(image_files)/BATCH_SIZE)):\n",
        "  initial_images = []\n",
        "  segmented_images = []\n",
        "  image_file_batch = image_files[stride*BATCH_SIZE : (stride+1)*BATCH_SIZE].tolist()\n",
        "  for image_file in image_file_batch:\n",
        "    image = cv2.imread(BASE_PATH+\"TestSetPreprocessed/\" + image_file, cv2.IMREAD_GRAYSCALE)\n",
        "    initial_images.append(image)\n",
        "    mask = model[0].predict(get_max_non_zero_image(image))\n",
        "    segmented_images.append(np.uint8(np.squeeze(np.squeeze(mask, axis=0), axis=2)*255))\n",
        "  printExampleImages(initial_images, image_file_batch)\n",
        "  printExampleImages(segmented_images, image_file_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjGh0R4I8jSx"
      },
      "source": [
        "## Add false negative images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aACQd6dx8rgE"
      },
      "outputs": [],
      "source": [
        "additional_images_to_be_saved = [\n",
        "                                 [\"P_3_178.png\", True],\n",
        "                                 [\"P_3_3.png\", False],\n",
        "                                 [\"P_3_78.png\", True],\n",
        "                                 [\"P_3_58.png\", True],\n",
        "                                 [\"P_3_390.png\", True],\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3YpY82zM8rgF",
        "outputId": "aa62821e-2997-4f2a-8bb8-3e6bbd22a167"
      },
      "outputs": [],
      "source": [
        "corrected_images = []\n",
        "\n",
        "for image_file, to_be_inverted in additional_images_to_be_saved:\n",
        "  image = cv2.imread(BASE_PATH+\"TestSetPreprocessed/\"+image_file, cv2.IMREAD_GRAYSCALE)\n",
        "  showImage(image, image_file)\n",
        "  if to_be_inverted:\n",
        "    image = 255 - image\n",
        "  image = np.expand_dims(np.expand_dims(image / 255, axis = 0), axis=3)\n",
        "  corrected_images.append(image)\n",
        "  image = np.squeeze(np.squeeze(np.uint8(model[0].predict(image) * 255), axis = 0), axis = 2)\n",
        "  showImage(image, image_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISuxWJ9k-E3I",
        "outputId": "e46e9793-c715-4d2c-9367-dddfb387b1fb"
      },
      "outputs": [],
      "source": [
        "bs_score = []\n",
        "\n",
        "for index, image in enumerate(corrected_images):\n",
        "  print(\"\\rProcessing: \"+str(index+1)+\"/\"+str(len(corrected_images)), end=\"\")\n",
        "  bs_score.append(np.squeeze(model[-1].predict(image), axis = 0))\n",
        "bs_score = np.array(bs_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZLcPvKl-E3J"
      },
      "outputs": [],
      "source": [
        "argmax = np.argmax(bs_score, axis = 3)\n",
        "argmax = np.reshape(argmax, (len(corrected_images), 6))\n",
        "probabilities = np.max(bs_score, axis = 3)\n",
        "probabilities = np.reshape(probabilities, (len(corrected_images), 6))\n",
        "confidence = np.mean(probabilities, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-yYzQ3J-E3K",
        "outputId": "9d70c21c-316a-442c-ee47-abedda3270bf"
      },
      "outputs": [],
      "source": [
        "for i in range(len(corrected_images)):\n",
        "  index = df_test[df_test.ImageFile == additional_images_to_be_saved[i][0]].index[0]\n",
        "  print(\"Index: \", index)\n",
        "  for j in range(6):\n",
        "    df_test.at[index, \"Brixia_score_\"+str(j)] = argmax[i,j]\n",
        "  for j in range(6):\n",
        "    df_test.at[index, \"Brixia_score_prob_\"+str(j)] = probabilities[i,j]\n",
        "  df_test.at[index, \"Brixia_score_correctness\"] = 1\n",
        "  df_test.at[index, \"Brixia_score_confidence\"] = confidence[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTsCrsoj-E3K",
        "outputId": "8e8346a5-d0cb-49e4-a2c4-c6c09a2aef97"
      },
      "outputs": [],
      "source": [
        "df_test.to_excel(BASE_PATH + \"Candidate_TestSet_brixiascore.xls\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bduSqCjxi6hm"
      },
      "source": [
        "# Can we detect if an image is inverted from its histogram?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "pbkhLD8xi55L",
        "outputId": "6bae477b-df0d-4375-ed15-e1970ea151cf"
      },
      "outputs": [],
      "source": [
        "PATH = BASE_PATH + \"TrainSetAdjusted/\"\n",
        "\n",
        "file_names = os.listdir(PATH)\n",
        "\n",
        "file_names = file_names[:4]\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i, file_name in enumerate(file_names):\n",
        "  image = cv2.imread(PATH + file_name, cv2.IMREAD_GRAYSCALE)\n",
        "  ax = plt.subplot(4, 4, i*4+1)\n",
        "  plt.imshow(image, cmap = 'gray', interpolation = 'bicubic', vmin=0, vmax=255)\n",
        "  ax.set_title(file_name)\n",
        "  plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
        "\n",
        "  ax = plt.subplot(4, 4, i*4+3)\n",
        "  plt.hist(image.ravel(),256,[0,256]);\n",
        "  ax.set_title(file_name)\n",
        "  plt.xticks([])\n",
        "\n",
        "  image = 255 - image\n",
        "  ax = plt.subplot(4, 4, i*4+2)\n",
        "  plt.imshow(image, cmap = 'gray', interpolation = 'bicubic', vmin=0, vmax=255)\n",
        "  ax.set_title(file_name + \" inverted\")\n",
        "  plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
        "\n",
        "  ax = plt.subplot(4, 4, i*4+4)\n",
        "  plt.hist(image.ravel(),256,[0,256]);\n",
        "  ax.set_title(file_name + \" inverted\")\n",
        "  plt.xticks([])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2Clo_fqoQkr"
      },
      "source": [
        "# Explainability maps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T22yVNO9oT26"
      },
      "outputs": [],
      "source": [
        "TF_BATCH_SIZE = 1\n",
        "\n",
        "def get_explainability_map(image, idx=None):\n",
        "\n",
        "    logger.info(\"Explainability map extraction\")\n",
        "    logger.debug(f\"Image shape: {image.shape}\")\n",
        "    bsp = model[-1].predict(image)[0]\n",
        "    seg = model[0].predict(image)[0]\n",
        "\n",
        "    logger.debug(\"Get SLIC\")\n",
        "    segments = slic(Image.fromarray(255 * image[0, :, :, 0]).convert('RGB'),\n",
        "                        n_segments=180, compactness=10, sigma=1)\n",
        "\n",
        "    segments = (seg[:, :, 0] > .5) * segments #tweak\n",
        "    logger.debug(f\"SLIC done, found {len(np.unique(segments)[1:])} segments\")\n",
        "\n",
        "    logger.debug(\"Get predictions for explainability\")\n",
        "    mimages = []\n",
        "\n",
        "    requests = []\n",
        "    for i, z in enumerate(np.unique(segments)[1:]):\n",
        "        mimage = image[0, :, :, 0] * (1 - (segments == z))\n",
        "        mimages.append(mimage)\n",
        "\n",
        "    resp = model[-1].predict(np.expand_dims(mimages, axis=-1))\n",
        "\n",
        "    assert len(resp) > 10, logger.error('The segmentation did not found anything. Probably a wrong image?')\n",
        "\n",
        "    p = np.array(resp)\n",
        "    logger.debug(f\"Predictions done. len(predictions): {len(resp)}\")\n",
        "\n",
        "    col_dict_class = [(15, 250, 20), (255, 215, 0), (149, 31, 22), (38, 38, 38)]\n",
        "\n",
        "    w = (bsp - p).max(axis=(1, 2))  # take the max (future: consider also the mean)\n",
        "    w = np.clip(w, 0, 1)  # take the positive only (the superpixel is respondible for the class)\n",
        "    w /= w.max()\n",
        "    wneg = (p - bsp).max(axis=(1, 2))  # take the max (future: consider also the mean)\n",
        "    wneg = np.clip(wneg, 0, 1)\n",
        "    wneg /= wneg.max()\n",
        "    dispersion = np.std(bsp - p, axis=-1)\n",
        "\n",
        "    pr = np.zeros((512, 512, 4))\n",
        "    cmaps = np.ones((512, 512, 3))\n",
        "    cmaps += np.expand_dims(segments == 0, axis=-1) * np.array([245, 245, 245])\n",
        "    cmaps_neg = cmaps.copy()\n",
        "    dispersion_map = np.zeros((512, 512, 1))\n",
        "    cmaps_map = np.zeros((512, 512, 1))\n",
        "    pmaps = np.zeros((512, 512, 1))\n",
        "\n",
        "    for i, z in enumerate(np.unique(segments)[1:]):\n",
        "        # if np.sum(segments==z)>256:\n",
        "        pr += np.expand_dims(segments == z, axis=-1) * w[i]  # np.sum(p[-1], axis=(0,1,2))\n",
        "\n",
        "        cmaps += np.expand_dims(segments == z, axis=-1) * np.array(col_dict_class[np.argmax(w[i])])\n",
        "        cmaps_neg += np.expand_dims(segments == z, axis=-1) * np.array(col_dict_class[np.argmax(wneg[i])])\n",
        "        cmaps_map += np.expand_dims(segments == z, axis=-1) * np.argmax(w[i])\n",
        "        pmaps += np.expand_dims(segments == z, axis=-1) * w[i].max()\n",
        "\n",
        "        dispersion_map += np.expand_dims(segments == z, axis=-1) * dispersion[i].max()\n",
        "\n",
        "    cmaps[cmaps > 1] = cmaps[cmaps > 1] - 1\n",
        "    cmaps_neg[cmaps_neg > 1] = cmaps_neg[cmaps_neg > 1] - 1\n",
        "\n",
        "    contours = measure.find_contours(seg[:, :, 0], 0.5)\n",
        "    mx = dispersion_map.max()\n",
        "    for contour in contours:\n",
        "        rr, cc = polygon_perimeter(contour[:, 0], contour[:, 1], cmaps.shape)\n",
        "        cmaps[rr, cc] = (0, 0, 100)\n",
        "        dispersion_map[rr, cc] = mx\n",
        "\n",
        "    expl_map = np.dstack(\n",
        "        (cmaps.astype('uint8'), (255 * dispersion_map / dispersion_map.max()).astype('uint8')[:, :, 0]))\n",
        "    logger.debug(\"[EME] completed.\")\n",
        "\n",
        "    return Image.fromarray(expl_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhzYEOlNEDhI"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(BASE_PATH+\"TrainSetAdjusted/P_1_60.png\", cv2.IMREAD_GRAYSCALE)\n",
        "image = np.expand_dims(np.expand_dims(image / 255, axis=0), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYCAlnJnEFRO",
        "outputId": "fc220485-77ef-4c86-e19f-375298446c78"
      },
      "outputs": [],
      "source": [
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "lOwfw4JZEJvp",
        "outputId": "8f2e4b4d-d2ae-4029-e975-5647e2a8ca8f"
      },
      "outputs": [],
      "source": [
        "get_explainability_map(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CaRJUZkaE_7"
      },
      "outputs": [],
      "source": [
        "bs_score = np.squeeze(model[-1].predict(image), axis = 0)\n",
        "argmax = np.argmax(bs_score, axis = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "_hxKoSJdaFX5",
        "outputId": "65b14a6f-5588-4539-8b12-70d72358fa50"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(argmax, cmap = 'Reds')\n",
        "# Loop over data dimensions and create text annotations.\n",
        "for i in range(argmax.shape[0]):\n",
        "    for j in range(argmax.shape[1]):\n",
        "        color = \"k\" if argmax[i, j] <=1 else \"w\"\n",
        "        ax.text(j, i, argmax[i, j], ha=\"center\", va=\"center\", color=color, size=\"xx-large\")\n",
        "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeECA7EmUZTS"
      },
      "source": [
        "# EXTRA: improve algorithm (not done)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeMzhGxrUu_m"
      },
      "source": [
        "Here the initial goal is to tune the algorithm in order to understand why it discard some good image. This is partially developed. The motivations behind each rejection are all different. It take a lot of time for just a little gain (21 false positive images out of 1600 --> 1.3% of the images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVwQXua2EU7k"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(BASE_PATH+\"BadImages/P_626.png\", cv2.IMREAD_GRAYSCALE)\n",
        "#adapted_image = 1 - np.expand_dims(np.expand_dims(image / 255, axis=2), axis=0)\n",
        "adapted_image = np.expand_dims(np.expand_dims(image / 255, axis=2), axis=0)\n",
        "mask = model[0].predict(adapted_image)\n",
        "mask = np.squeeze(np.squeeze(mask, axis=0), axis=2)\n",
        "# Use the 0-255 pixel value range\n",
        "mask = denormalizeImage(mask)\n",
        "# Erode the mask\n",
        "mask = cv2.erode(mask, np.ones((3,3), np.uint8), iterations=3)\n",
        "# Find connected components\n",
        "num_regions, labels, stats, _ = cv2.connectedComponentsWithStats(mask, 8, cv2.CV_32S)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "S0d7PVuCDKnB",
        "outputId": "6ae4d50e-1c04-440c-ecb7-0cdbbcb9fe20"
      },
      "outputs": [],
      "source": [
        "showImage(mask, \"Mask\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "SiUui8F8DeoI",
        "outputId": "540b4693-c9c3-4aa7-9448-b34f21bc75bc"
      },
      "outputs": [],
      "source": [
        "canny_output = cv2.Canny(mask, 100, 200)\n",
        "contours, _ = cv2.findContours(canny_output, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "# Keep just the 2 longest contours\n",
        "argsort_contour = np.argsort([len(val) for val in contours])[::-1]#[-2:]\n",
        "# Redefine contours with just the 2 longest contours\n",
        "contours = [contours[i] for i in argsort_contour]\n",
        "# Find the ellipses for each contour\n",
        "minEllipses = [None]*len(contours)\n",
        "for i, c in enumerate(contours):\n",
        "  if c.shape[0] > 5:\n",
        "    minEllipses[i] = cv2.fitEllipse(c)\n",
        "\n",
        "# Draw contours + rotated rects + ellipses\n",
        "    \n",
        "drawing = np.zeros((canny_output.shape[0], canny_output.shape[1], 3), dtype=np.uint8)\n",
        "    \n",
        "for i, c in enumerate(contours):\n",
        "  color = 255, 255, 255\n",
        "  # contour\n",
        "  cv2.drawContours(drawing, contours, i, color)\n",
        "  # ellipse\n",
        "  if c.shape[0] > 5:\n",
        "    cv2.ellipse(drawing, minEllipses[i], color, 2)\n",
        "showImage(drawing, \"Fitted ellipse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8X5SjwmYGFpl"
      },
      "outputs": [],
      "source": [
        "contours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "aSr4yUqiGqPi",
        "outputId": "9605f453-206b-4f30-a376-2cbb13132e68"
      },
      "outputs": [],
      "source": [
        "canny_output = cv2.Canny(mask, 100, 200)\n",
        "contours, _ = cv2.findContours(canny_output, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "argsort_contour = np.argsort([len(val) for val in contours])[::-1]\n",
        "contours = [contours[i] for i in argsort_contour]\n",
        "\n",
        "if len(contours) > 3:\n",
        "  contours = contours[:3]\n",
        "\n",
        "minEllipses = [None]*len(contours)\n",
        "for i, c in enumerate(contours):\n",
        "  if c.shape[0] > 5:\n",
        "    minEllipses[i] = cv2.fitEllipse(c)\n",
        "  \n",
        "ellipses = [None]*2\n",
        "ellipses[0] = minEllipses[0]\n",
        "\n",
        "if len(contours) > 2 and np.abs(len(contours[2])-len(contours[1])) < 50 :\n",
        "  if np.tan(np.deg2rad(90 - minEllipses[0][2])) * np.tan(np.deg2rad(90 - minEllipses[1][2])) < 0:\n",
        "    ellipses[1] = minEllipses[1]\n",
        "  else:\n",
        "    ellipses[1] = minEllipses[2]\n",
        "else:\n",
        "  ellipses[1] = minEllipses[1]\n",
        "\n",
        "# Draw contours + rotated rects + ellipses\n",
        "    \n",
        "drawing = np.zeros((canny_output.shape[0], canny_output.shape[1], 3), dtype=np.uint8)\n",
        "\n",
        "color = 255, 255, 255 \n",
        "for i, c in enumerate(contours):\n",
        "  # contour\n",
        "  cv2.drawContours(drawing, contours, i, color)\n",
        "\n",
        "for i, c in enumerate(ellipses):\n",
        "  cv2.ellipse(drawing, ellipses[i], color, 2)\n",
        "\n",
        "showImage(drawing, \"New algorithm\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "mZ1jamyVxnwr",
        "VXpQnsym7zbQ",
        "Wy0ZsX7gyxya",
        "gt2BAMXQ5ZOO",
        "_GOtmIxkDwq9",
        "glsilLjmZQ5A",
        "RHHVV12CZLW7",
        "lKgI27VBV0Zm",
        "v-kAwWShd0xD",
        "HUma8_s7goL8",
        "LwlfThPlDkw0",
        "FtOYXnh_LPEM",
        "371NFD1K5WVt",
        "LMBiwnets9N8",
        "qzwqPqNx2ufi",
        "bduSqCjxi6hm",
        "r2Clo_fqoQkr",
        "AeECA7EmUZTS"
      ],
      "name": "Image elaboration and BsNet Experiments.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
