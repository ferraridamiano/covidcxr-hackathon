{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing_numerical_comparison.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Numerical comparison between different methods"
      ],
      "metadata": {
        "id": "edFCUl4h6gVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This colab shows what is the best method between RANSAC, LS and ellipse fitting as test for assess lungs direction. The output images are compare with reference images that are manually adjusted. It discerns between correct images, wrong images (adjusted but wrongly) and discarded images (the algorithm was not able to find a solution)**"
      ],
      "metadata": {
        "id": "OJrLIEiu6kyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Keras-Applications"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wcyv0BFiMz7H",
        "outputId": "cdebdd00-d684-4470-83e1-5be3fd497e74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Keras-Applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras-Applications) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-Applications) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras-Applications) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AQLOlebxu-V"
      },
      "source": [
        "Clone BrixIA from Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBRh7KZjtzKc",
        "outputId": "fb024dde-6e51-44d1-f1e2-2bcca0a4cde1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Brixia-score-COVID-19' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone 'https://github.com/BrixIA/Brixia-score-COVID-19'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C3idXRox1d8"
      },
      "source": [
        "Include BrixIA in sys.path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "705rkd06tow9"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/Brixia-score-COVID-19/src\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iYYzpU2yCzx"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ii_GwpP_uQrW"
      },
      "outputs": [],
      "source": [
        "from BSNet.model import BSNet\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import linear_model\n",
        "import shutil\n",
        "import os\n",
        "from skimage.segmentation import slic\n",
        "from skimage.draw import polygon_perimeter\n",
        "from skimage import measure\n",
        "\n",
        "BASE_PATH = \"/content/drive/Shareddrives/IDA covidcxr-hackaton/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6On4JXYTzLnV"
      },
      "source": [
        "Mount GDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd1kiFeNzK9G",
        "outputId": "4b493cec-a7bb-4716-8f58-9647574676a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy0ZsX7gyxya"
      },
      "source": [
        "# Load the model with the weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3Gwje_My2RJ",
        "outputId": "ec0554fd-cde4-428c-a700-61eee0db60f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading segmentation model\n",
            "Loading alignment model\n",
            "Loading BScore model\n"
          ]
        }
      ],
      "source": [
        "# Create the model with preloaded weights\n",
        "# MAE: 0.48\n",
        "model = BSNet(backbone_name='resnet18',\n",
        "              input_shape=(512, 512, 1),\n",
        "              input_tensor=None,\n",
        "              encoder_weights=None,\n",
        "              freeze_encoder=True,\n",
        "              skip_connections='default',\n",
        "              decoder_block_type='transpose',\n",
        "              decoder_filters=(256, 128, 64, 32, 16),\n",
        "              decoder_use_batchnorm=True,\n",
        "              n_upsample_blocks=5,\n",
        "              upsample_rates=(2, 2, 2, 2, 2),\n",
        "              classes=4,\n",
        "              activation='sigmoid',\n",
        "              load_seg_model=True,\n",
        "              seg_model_weights=BASE_PATH+'weights/segmentation-model.h5',\n",
        "              freeze_segmentation=True,\n",
        "              load_align_model=True,\n",
        "              align_model_weights=BASE_PATH+'weights/alignment-model.h5',\n",
        "              freeze_align_model=True,\n",
        "              pretrain_aligment_net=False,\n",
        "              explict_self_attention=True,\n",
        "              load_bscore_model=True,\n",
        "              bscore_model_weights=BASE_PATH+'weights/fpn_4lev_fliplr_ncl_loss03_correct_feat128-16-44.h5',\n",
        "              )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXpQnsym7zbQ"
      },
      "source": [
        "# Utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l8PzhQq71IP"
      },
      "outputs": [],
      "source": [
        "def showImage(image, title=\"\"):\n",
        "  \"\"\"\n",
        "  Shows an image adding the desired title\n",
        "  \n",
        "  Parameters\n",
        "  ----------\n",
        "  image: numpy.ndarray\n",
        "    The image to be shown\n",
        "  title: string\n",
        "    The title to be shown for the plotted image\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  None\n",
        "  \"\"\"\n",
        "  \n",
        "  if image.ndim == 2:\n",
        "    plt.imshow(image, cmap = 'gray', interpolation = 'bicubic', vmin=0, vmax=255)\n",
        "  else:\n",
        "    plt.imshow(image, interpolation = 'bicubic', vmin=0, vmax=255)\n",
        "    \n",
        "  plt.title(title)\n",
        "  plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def denormalizeImage(image):\n",
        "  return np.uint8(np.where(image<0.5, 0, 255))"
      ],
      "metadata": {
        "id": "wiewwR_i4cFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lungs_direction_test(image, connectedComponents=None, assessment_mode=\"ellipse_fitting\") -> bool:\n",
        "  if connectedComponents is None:\n",
        "    num_regions, labels, stats, _ = cv2.connectedComponentsWithStats(image, 8, cv2.CV_32S)\n",
        "  else:\n",
        "    num_regions, labels, stats, _ = connectedComponents\n",
        "  \n",
        "  if num_regions < 3:\n",
        "    return False\n",
        "  argsort = np.argsort(stats[:, -1])[::-1]\n",
        "\n",
        "  if assessment_mode == \"least_square\":\n",
        "    lung_1 = np.argwhere(labels==argsort[1])\n",
        "    y_lung_1 = lung_1[:,0]\n",
        "    x_lung_1 = lung_1[:,1]\n",
        "    lung_2 = np.argwhere(labels==argsort[2])\n",
        "    y_lung_2 = lung_2[:,0]\n",
        "    x_lung_2 = lung_2[:,1]\n",
        "    slope_1, intercept_1 = np.polyfit(x_lung_1, -y_lung_1, 1)\n",
        "    slope_2, intercept_2 = np.polyfit(x_lung_2, -y_lung_2, 1)\n",
        "\n",
        "  elif assessment_mode == \"ransac\":\n",
        "    lung_1 = np.argwhere(labels==argsort[1])\n",
        "    y_lung_1 = lung_1[:,0]\n",
        "    x_lung_1 = lung_1[:,1]\n",
        "    lung_2 = np.argwhere(labels==argsort[2])\n",
        "    y_lung_2 = lung_2[:,0]\n",
        "    x_lung_2 = lung_2[:,1]\n",
        "    ransac_1 = linear_model.RANSACRegressor(linear_model.LinearRegression())\n",
        "    ransac_1.fit(x_lung_1.reshape(-1,1), -y_lung_1)\n",
        "    ransac_2 = linear_model.RANSACRegressor(linear_model.LinearRegression())\n",
        "    ransac_2.fit(x_lung_2.reshape(-1,1), -y_lung_2)\n",
        "    slope_1 = ransac_1.estimator_.coef_[0]\n",
        "    slope_2 = ransac_2.estimator_.coef_[0]\n",
        "    intercept_1 = ransac_1.predict([[0]])[0]\n",
        "    intercept_2 = ransac_2.predict([[0]])[0]\n",
        "\n",
        "  elif assessment_mode == \"ellipse_fitting\":\n",
        "    lungs = np.uint8(np.where(np.logical_or(np.equal(labels, argsort[1]), np.equal(labels, argsort[2])), 255, 0))\n",
        "    canny_output = cv2.Canny(lungs, 100, 200)\n",
        "    contours, _ = cv2.findContours(canny_output, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    # Keep just the 2 longest contours\n",
        "    argsort_contour = np.argsort([len(val) for val in contours])[-2:]\n",
        "    # Redefine contours with just the 2 longest contours\n",
        "    contours = [contours[i] for i in argsort_contour]\n",
        "    # Find the ellipses for each contour\n",
        "    minEllipses = [None]*len(contours)\n",
        "    for i, c in enumerate(contours):\n",
        "      if c.shape[0] > 5:\n",
        "        minEllipses[i] = cv2.fitEllipse(c)\n",
        "    slope_1 = np.tan(np.deg2rad(90 - minEllipses[0][2]))\n",
        "    slope_2 = np.tan(np.deg2rad(90 - minEllipses[1][2]))\n",
        "    intercept_1 = -minEllipses[0][0][1] - slope_1 * minEllipses[0][0][0]\n",
        "    intercept_2 = -minEllipses[1][0][1] - slope_2 * minEllipses[1][0][0]\n",
        "\n",
        "  else:\n",
        "    raise ValueError('assessment_mode must be either least_square, ransac or ellipse_fitting')\n",
        "\n",
        "  x_intersection = (intercept_2 - intercept_1) / (slope_1 - slope_2)\n",
        "  y_intersection = slope_1 * x_intersection + intercept_1\n",
        "\n",
        "  if y_intersection > -256 and x_intersection > 0 and x_intersection < 512:\n",
        "    return True\n",
        "  return False"
      ],
      "metadata": {
        "id": "Vdqyd6FHQHNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Brute-force lungs segmentation assessment\n",
        "def adjust_preprocessed_image(image, assessment_mode=\"ellipse_fitting\", num_pixels_lung=10000):\n",
        "  # Adapt to the dimensions requested by BSNet\n",
        "  adapted_image = np.expand_dims(np.expand_dims(image / 255, axis=2), axis=0)\n",
        "  # most images are not rotated (0), few of them are rotate buy just 90 degrees (3, 1),\n",
        "  # almost none of them are rotated by 180 degree (2)\n",
        "  for rotation_count in [0, 3, 1, 2]:\n",
        "    rotated_image = np.rot90(adapted_image, k=rotation_count, axes=(1,2))\n",
        "    for pos_neg in [False, True]:\n",
        "      if pos_neg:\n",
        "        rotated_image = 1 - rotated_image\n",
        "      mask = model[0].predict(rotated_image)\n",
        "      # Go back to 512x512 image format\n",
        "      mask = np.squeeze(np.squeeze(mask, axis=0), axis=2)\n",
        "      # Use the 0-255 pixel value range\n",
        "      mask = denormalizeImage(mask)\n",
        "      # Erode the mask\n",
        "      mask = cv2.erode(mask, np.ones((3,3), np.uint8), iterations=3)\n",
        "      # Find connected components\n",
        "      connectedComponents = cv2.connectedComponentsWithStats(mask, 8, cv2.CV_32S)\n",
        "      num_regions, _, stats, _ = connectedComponents\n",
        "      # Sort stats by the last column\n",
        "      argsort = np.argsort(stats[:, -1])[::-1]\n",
        "      stats = stats[argsort]\n",
        "      # If the first and the second region has at least 10000 pixel then it's ok\n",
        "      if num_regions>=3 and stats[1][-1] > num_pixels_lung and stats[2][-1] > num_pixels_lung:\n",
        "        if(lungs_direction_test(mask, connectedComponents=connectedComponents, assessment_mode=assessment_mode)):\n",
        "          return np.squeeze(np.squeeze(np.uint8(rotated_image * 255), axis = 0), axis = 2)\n",
        "  return None"
      ],
      "metadata": {
        "id": "VepYijCwhlYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read files"
      ],
      "metadata": {
        "id": "mMNJjwGCUxQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_path = BASE_PATH+\"TrainSetPreprocessed/\"\n",
        "adjusted_path = BASE_PATH+\"TrainSetAdjusted/\"\n",
        "images_filenames = os.listdir(preprocessed_path)\n",
        "number_total_images = len(images_filenames)"
      ],
      "metadata": {
        "id": "RZC2E4B0U0MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Least square"
      ],
      "metadata": {
        "id": "s0zPYz08K1Dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_correct_images = 0\n",
        "number_discarded_images = 0\n",
        "number_wrong_images = 0\n",
        "\n",
        "for index, image_filename in enumerate(images_filenames):\n",
        "  image = cv2.imread(preprocessed_path+image_filename, cv2.IMREAD_GRAYSCALE)\n",
        "  corrected_image = cv2.imread(adjusted_path+image_filename, cv2.IMREAD_GRAYSCALE)\n",
        "  output_image = adjust_preprocessed_image(image, assessment_mode=\"least_square\")\n",
        "  if output_image is None:\n",
        "    number_discarded_images +=1\n",
        "  elif np.array_equal(output_image, corrected_image):\n",
        "    number_correct_images +=1\n",
        "  else:\n",
        "    number_wrong_images +=1\n",
        "\n",
        "  print(\"\\r\"+str(index+1)+\"/\"+str(number_total_images)+\";  Correct images = \"+str(number_correct_images)+\";  Discarded images = \"+str(number_discarded_images)+\";  Wrong images = \"+str(number_wrong_images), end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8YZPVIJMjT4",
        "outputId": "fd458b1e-4e3c-4f0d-dcf1-87a1f6a572ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1103/1103;  Correct images = 955;  Discarded images = 91;  Wrong images = 57"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RANSAC"
      ],
      "metadata": {
        "id": "S5lel8d_VoP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_correct_images = 0\n",
        "number_discarded_images = 0\n",
        "number_wrong_images = 0\n",
        "\n",
        "for index, image_filename in enumerate(images_filenames):\n",
        "  image = cv2.imread(preprocessed_path+image_filename, cv2.IMREAD_GRAYSCALE)\n",
        "  corrected_image = cv2.imread(adjusted_path+image_filename, cv2.IMREAD_GRAYSCALE)\n",
        "  output_image = adjust_preprocessed_image(image, assessment_mode=\"ransac\")\n",
        "  if output_image is None:\n",
        "    number_discarded_images +=1\n",
        "  elif np.array_equal(output_image, corrected_image):\n",
        "    number_correct_images +=1\n",
        "  else:\n",
        "    number_wrong_images +=1\n",
        "\n",
        "  print(\"\\r\"+str(index+1)+\"/\"+str(number_total_images)+\";  Correct images = \"+str(number_correct_images)+\";  Discarded images = \"+str(number_discarded_images)+\";  Wrong images = \"+str(number_wrong_images), end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYrLC3yFVwJy",
        "outputId": "658a335b-eb95-42cb-a5dd-14099267eb99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1103/1103;  Correct images = 917;  Discarded images = 121;  Wrong images = 65"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ellipses fitting"
      ],
      "metadata": {
        "id": "0CdasVKNV78N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_correct_images = 0\n",
        "number_discarded_images = 0\n",
        "number_wrong_images = 0\n",
        "\n",
        "bad_images = []\n",
        "\n",
        "for index, image_filename in enumerate(images_filenames):\n",
        "  image = cv2.imread(preprocessed_path+image_filename, cv2.IMREAD_GRAYSCALE)\n",
        "  corrected_image = cv2.imread(adjusted_path+image_filename, cv2.IMREAD_GRAYSCALE)\n",
        "  output_image = adjust_preprocessed_image(image, assessment_mode=\"ellipse_fitting\")\n",
        "  if output_image is None:\n",
        "    number_discarded_images +=1\n",
        "    bad_images.append(image_filename)\n",
        "  elif np.array_equal(output_image, corrected_image):\n",
        "    number_correct_images +=1\n",
        "  else:\n",
        "    bad_images.append(image_filename)\n",
        "    number_wrong_images +=1\n",
        "\n",
        "  print(\"\\r\"+str(index+1)+\"/\"+str(number_total_images)+\";  Correct images = \"+str(number_correct_images)+\";  Discarded images = \"+str(number_discarded_images)+\";  Wrong images = \"+str(number_wrong_images), end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb5QwYDiV78O",
        "outputId": "0fa464e1-9bbb-4861-ddb4-322486305ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "903/1103;  Correct images = 798;  Discarded images = 77;  Wrong images = 28"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: RuntimeWarning: divide by zero encountered in double_scalars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1103/1103;  Correct images = 971;  Discarded images = 101;  Wrong images = 31"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image_filename in bad_images:\n",
        "  image = cv2.imread(preprocessed_path+image_filename, cv2.IMREAD_GRAYSCALE)\n",
        "  output_image = adjust_preprocessed_image(image, assessment_mode=\"ellipse_fitting\")\n",
        "  showImage(image, \"\")"
      ],
      "metadata": {
        "id": "hgg3jucpYc-i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}